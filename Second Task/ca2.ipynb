{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "128b2309",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "96abb787fc0f1d4454b516efe2997ee3",
     "grade": false,
     "grade_id": "cell-bcb7a0d7b1517f6b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# ECMM422 Machine Learning\n",
    "## Course Assessment 2\n",
    "\n",
    "This course assessment (CA) represents 60% of the overall module assessment.\n",
    "\n",
    "This is an individual exercise and your attention is drawn to the College and University guidelines on collaboration and plagiarism, which are available from the [College website](https://www.exeter.ac.uk/students/administration/complaintsandappeals/academicmisconduct/). \n",
    "Students are **not allowed** to use Large Language Models (such as ChatGPT, Claude, Gemini, etc) to generate code for the CA.\n",
    "\n",
    "\n",
    "**Submission information:**\n",
    "1. do not change the name of this notebook, i.e. the notebook file has to be: `ca2.ipynb`\n",
    "2. do not add you name or student code in the notebook or in the file name\n",
    "3. do not remove or delete or add any cell in this notebook\n",
    "4. make sure to **remove** and **delete** the `raise NotImplementedError()` under the `# YOUR CODE HERE` and replace it with **your code**: note that if you leave it in the cell you will fail the associated test\n",
    "5. do not remove the function `save_history()` at the end of each cell. This function will save your edit operations on the code in the cell and will be used as proof of work, i.e. proof that you have been working on the questions assigned\n",
    "6. work always in the cells provided when developing your implementation, i.e. do not work on another notebook or with programming environments that do not operate on this notebook.\n",
    "7. when you are finished debugging **remove** all code that is not part of the function definition, i.e. leave only the clean function implementation in the cell: do not leave debugging `print` statements in the functions, and do not leave function invocations on test inputs\n",
    "8. make sure that the execution of the cell **does not produce any type of output**: the execution of the cell should only define the desired functions\n",
    "9. before the final submission run the function `check_and_prepare_for_submission()` in the last cell of the notebook: this function will create a zip archive called `ecmm422ca2.zip` which contains your notebook and the folder `proof_of_work`.\n",
    "10. Submit only the file `ecmm422ca2.zip`\n",
    "\n",
    "\n",
    "**Evaluation criteria:**\n",
    "\n",
    "Each question asks for one or more functions to be implemented. \n",
    "\n",
    "- Each function is awarded a number of marks. \n",
    "- One or more hidden unit tests are going to evaluate if all desired properties of the required function are met. \n",
    "- If the function passes a test all the associated marks are awarded, if it fails 0 marks are awarded.\n",
    "- If you make a typo error (e.g. misspelling a variable) this will likely causes a syntax error, the function execution will fail and you will be awarded 0 marks.\n",
    "- Do not make assumptions on the state of previous cells, i.e. expect each function to be evaluated independently, moreover expect each function to be tested in the unit tests on some *randomly* generated input.\n",
    "\n",
    "Although the test use a hard fail/pass strategy to assign marks, the presence of several questions and several unit tests per question allows a fine grading. \n",
    "\n",
    "The Checkpoints are not graded by default, but might be used to assign additional marks in case the execution of the code obtains the desired results even when some tests might fail.\n",
    "\n",
    "**Efficiency:** There is a cap of a few minutes on the execution of each cell and unit test. Make sure your code is not terribly inefficient (for example having a cell run for hours, e.g. using nested loops rather than NumPy functions that can work directly on  arrays), otherwise the execution of the cell/unit test will be interrupted and considered a failure. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee280d04",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "676bfed739af111a9c038e65f57910fa",
     "grade": false,
     "grade_id": "cell-192dfe5e6e653c94",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Conventions and notation:\n",
    "\n",
    "Do not assume any library is avaialble other than `matplotlib`, `numpy`, `scipy`.\n",
    "\n",
    "Assume Python 3.8.\n",
    "\n",
    "---\n",
    "\n",
    "In the rest of the notebook, the term `data matrix` refers to a two dimensional numpy array where instances are encoded as rows, e.g. a data matrix with 100 rows and 4 columns is to be interpreted as a collection of 100 instances (vectors) each of dimension four.\n",
    "\n",
    "Make sure to convert numpy `matrix` objects to numpy arrays when returning a data matrix: only arrays are acceptable, not  numpy `matrix` objects. \n",
    "\n",
    "In the rest of the notebook, the term `vector` refers to a **one** dimensional numpy array. \n",
    "\n",
    "When we explicitly use the term `column vector` we mean a two dimensional array of shape `(n,1)`, when we explicitly use the term `row vector` we mean a two dimensional vector of shape `(1,n)`.\n",
    "\n",
    "When the term `distance` is used we mean the Euclidean distance. \n",
    "\n",
    "The functions you are required to write often need to take in input and return as output such objects, i.e. numpy arrays, not python lists. Check the specifications for each required function in the question text. \n",
    "\n",
    "---\n",
    "\n",
    "**Do not use library functions** to directly solve a question unless explicity instructed to do so. That is, when a required function can be implemented directly by a library function it is intended that the candidate should write their own implementation of the function: for example it the Question asks to implement a function to compute the `accuracy` one cannot just wrap the function `accuracy_score` from `sklearn.metrics` in a custom function; if a question asks to implement the K-nearest_neighbor algorithm one cannot just wrap the function `KNeighborsClassifier` from `sklearn.neighbors` in a custom function.\n",
    "\n",
    "---\n",
    "\n",
    "Do not assume that the implementations provided in the Workshops exercises contain no mistakes. You should write and are ultimately responsible for the code that you submit in this Assessment.\n",
    "\n",
    "---\n",
    "\n",
    "You are asked to solve the quadratic optimization problem using the library [cvxopt](http://cvxopt.org/).  \n",
    "\n",
    "You can install the library via:\n",
    "\n",
    "`pip install cvxopt`\n",
    "\n",
    "or\n",
    "\n",
    "`conda install -c conda-forge cvxopt`\n",
    "\n",
    "Then you should be able to import the module with:\n",
    "\n",
    "    `import cvxopt`\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd54280",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T17:09:21.614550Z",
     "start_time": "2024-04-10T17:09:20.654608Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c25c5bf7f58b383602b1290b69b52f7e",
     "grade": false,
     "grade_id": "cell-5ff73730fa6ff9c3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import cvxopt\n",
    "from submission_utils import save_history, check_and_prepare_for_submission\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c7ad28",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4987841e6eb6b16ef606e65e0a0dde05",
     "grade": false,
     "grade_id": "cell-205ecc9459548545",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 1\n",
    "\n",
    "<div style=\"text-align: right\"><b>[12 marks]</b></div>\n",
    "\n",
    "**Sequence Generation and Perturbation**\n",
    "\n",
    "**Objective:**\n",
    "The objective of this section of the programming assignment is to implement various functions related to sequence generation, permutation, and perturbation. \n",
    "\n",
    "**Functions to Implement:**\n",
    "1. `permute(seq)`\n",
    "   - **Input:** `seq` - a sequence of characters\n",
    "   - **Output:** A randomly permuted version of the input sequence `seq`\n",
    "\n",
    "2. `generate_master_sequence(alphabet_size, seq_length, start_char=70)`\n",
    "   - **Input:**\n",
    "     - `alphabet_size`: Number of unique characters in the generated sequence\n",
    "     - `seq_length`: Length of the generated sequence\n",
    "     - `start_char`: ASCII value of the starting character in the sequence (default value is 70)\n",
    "   - **Output:** A randomly generated master sequence of the specified length and alphabet size\n",
    "\n",
    "3. `perturb(master_sequence, noise)`\n",
    "   - **Input:**\n",
    "     - `master_sequence`: The original sequence to be perturbed\n",
    "     - `noise`: A float value indicating the degree of perturbation to apply to the sequence\n",
    "   - **Output:** A perturbed version of the master sequence based on the specified noise level. To perturb a sequence you should repeatedly swap the position of two elements of the sequence at random. The parameter `noise` is a float that indicates the fraction of times that the swapping should take place. The actual number of times can be computed as `noise` * the number of elements of the input sequence. So if `noise=0.1` and the sequence has 200 elements, then the number of times that the swapping should take place is 20.\n",
    "\n",
    "4. `randomize_length(seqs, endpoint_trim_dim)`\n",
    "   - **Input:**\n",
    "     - `seqs`: A list of sequences\n",
    "     - `endpoint_trim_dim`: Maximum number of characters to trim from both ends of each sequence. A random number between 0 and `endpoint_trim_dim` is selected for\n",
    "     -  each end.\n",
    "   - **Output:** List of sequences with randomized lengths by trimming characters from both ends\n",
    "\n",
    "5. `make_single_cluster_data(master_sequence, n_inliners, n_outliers, inliner_noise, outlier_noise, endpoint_trim_dim=None)`\n",
    "   - **Input:**\n",
    "     - `master_sequence`: The original sequence representing the cluster center\n",
    "     - `n_inliners`: Number of inlier sequences to be generated\n",
    "     - `n_outliers`: Number of outlier sequences to be generated\n",
    "     - `inliner_noise`: Degree of noise to apply to inlier sequences\n",
    "     - `outlier_noise`: Degree of noise to apply to outlier sequences\n",
    "     - `endpoint_trim_dim`: Maximum number of characters to trim from both ends of each sequence (optional)\n",
    "   - **Output:** List of sequences containing inliers and outliers generated based on the master sequence and noise parameters\n",
    "\n",
    "6. `make_data(master_sequence, n_clusters, cluster_centres_noise, n_inliners, n_outliers, inliner_noise, outlier_noise, endpoint_trim_dim=None)`\n",
    "   - **Input:**\n",
    "     - `master_sequence`: The original sequence representing the cluster center\n",
    "     - `n_clusters`: Number of clusters to generate\n",
    "     - `cluster_centres_noise`: Degree of noise to apply to cluster center sequences\n",
    "     - `n_inliners`: Number of inliers per cluster\n",
    "     - `n_outliers`: Number of outliers per cluster\n",
    "     - `inliner_noise`: Degree of noise to apply to inlier sequences\n",
    "     - `outlier_noise`: Degree of noise to apply to outlier sequences\n",
    "     - `endpoint_trim_dim`: Maximum number of characters to trim from both ends of each sequence (optional)\n",
    "   - **Output:** Tuple containing:\n",
    "     - `seqs`: List of sequences representing the generated data. The total number of sequences produced is `(n_inliners + n_outliers ) * n_clusters`.\n",
    "     - `targets`: List of cluster labels corresponding to each sequence\n",
    "\n",
    "\n",
    "**Notes:**\n",
    "- The idea is to generate a master sequence of a certain lenght. This sequence has a random number of occurrences of `alphabet_size` distinct characters. This sequence will be used to generate all other sequences via perturbation.\n",
    "- In `make_single_cluster_data`, the idea is to generate a number `n_inliners + n_outliers` of sequence derived from the `master_sequence` in input. The inlier will be only slighlty perturbed, while the outliers will be greatly perturbed (this is controlled by the respective noise parameters). Note that there is no other difference between the inliners and the outliers apart from the amount of perturbation applied. \n",
    "- In `make_data` the idea is to start from the `master_sequence` in input and then generate a number `n_clusters` of derived master sequences. These will be used to seed each cluster. These sequences are not totally dissimilar, instead they will be generated as perturbations of the original master sequence by applying an amount of noise equal to `cluster_centres_noise`. So if a small amount of noise is applied, the centers of the clusters will be very similar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38690664",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T17:09:21.636587Z",
     "start_time": "2024-04-10T17:09:21.617497Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2f4f31ee9fe7f443a89450b42c931438",
     "grade": false,
     "grade_id": "cell-ce90b7321a56b8a1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "    \n",
    "def permute(seq):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def generate_master_sequence(alphabet_size, seq_length, start_char=70):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def perturb(master_sequence, noise):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def randomize_length(seqs, endpoint_trim_dim):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def make_single_cluster_data(master_sequence, n_inliners, n_outliers, inliner_noise, outlier_noise, endpoint_trim_dim=None):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def make_data(master_sequence, n_clusters, cluster_centres_noise, n_inliners, n_outliers, inliner_noise, outlier_noise, endpoint_trim_dim=None):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "save_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38efa0c-0842-4f1b-b599-a1531ec740dd",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "afa40462734f69b50388565bb0de8f62",
     "grade": true,
     "grade_id": "cell-eb65796d1ae9a3ad",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Do not consider this cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd99827-931f-4c2e-84de-d3cb7c4c4ddc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "203e4bf91f145a80a7fce2640666fe76",
     "grade": true,
     "grade_id": "cell-db8acdaf20165f54",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Do not consider this cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce61c673-a7c9-4451-8b45-37e82fe5a6c7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "21ced893ebbcab0c8c8ee2d6deaf7654",
     "grade": true,
     "grade_id": "cell-d21eeeff263c6a2b",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Do not consider this cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09d19e7-558d-4258-a461-fe04de6841ae",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1e643bc12077b2891ca079e606d786ae",
     "grade": true,
     "grade_id": "cell-e0d394661dff2b51",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Do not consider this cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54654877-6b9e-4dd8-bac8-6c82782073f5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0dbcbc080cd478bd11fa28e14fcf01d3",
     "grade": true,
     "grade_id": "cell-5284bdba44f0c1a3",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Do not consider this cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13351fd-6829-42d0-a1ac-1646d24b878b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8e17f9f18b43837f34955bce88091ff8",
     "grade": true,
     "grade_id": "cell-29f51260b2cfd59c",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Do not consider this cell. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13378f53",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9a51fed74c0f24c3881fe50c0da8bfe4",
     "grade": false,
     "grade_id": "cell-4fc62300616a0701",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 2\n",
    "\n",
    "<div style=\"text-align: right\"><b>[8 marks]</b></div>\n",
    "\n",
    "**Histogram Vectorizer and PCA Plotter**\n",
    "\n",
    "**Objective:**\n",
    "The objective of this section of the programming assignment is to implement various functions related to data preprocessing and visualization. Specifically, the candidate needs to implement a histogram vectorizer to convert sequences into numerical representations and a PCA plotter to visualize high-dimensional data in two dimensions.\n",
    "\n",
    "**Functions to Implement:**\n",
    "\n",
    "1. `histogram_vectorizer(seqs)`\n",
    "   - **Input:** \n",
    "     - `seqs`: A list of sequences (strings)\n",
    "   - **Output:** \n",
    "     - A matrix where each row represents the histogram vectorized representation of a sequence in the input list.\n",
    "   - **Description:** \n",
    "     - This function takes a list of sequences as input and converts each sequence into a histogram vectorized representation. It utilizes inner functions to facilitate the conversion process.\n",
    "\n",
    "2. `pca_plot(X, y=None)`\n",
    "   - **Input:** \n",
    "     - `X`: Data matrix where each row represents a sample and each column represents a feature.\n",
    "     - `y` (optional): Labels corresponding to each sample for color-coding in the plot.\n",
    "   - **Output:** \n",
    "     - A scatter plot visualizing the input data points after performing PCA (Principal Component Analysis) to reduce dimensionality to 2D.\n",
    "   - **Description:** \n",
    "     - This function takes a data matrix `X` and performs PCA to reduce the dimensionality to 2D. It then generates a scatter plot to visualize the data points. If labels `y` are provided, data points will be color-coded based on the labels.\n",
    "\n",
    "**Notes:**\n",
    "- Implement the inner functions (`convert_to_int_sequence` and `single_histogram_vectorizer`) within the `histogram_vectorizer` function.\n",
    "- Ensure that the implemented functions conform to the specified signatures and requirements.\n",
    "- Use appropriate libraries and data structures to efficiently implement the functions.\n",
    "- Validate the correctness and functionality of each function thoroughly.\n",
    "- Include comments and docstrings to explain the purpose and functionality of each function.\n",
    "- Consider edge cases and handle exceptions gracefully.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768bfb10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T17:09:22.256313Z",
     "start_time": "2024-04-10T17:09:21.638857Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0b55703d64999890685391e2e515821d",
     "grade": false,
     "grade_id": "cell-e2fb2b1b24c0785b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def histogram_vectorizer(seqs):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def pca_plot(X, y=None):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "save_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed73978-0176-486c-a928-3be32c98a32c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b9bc224060a056974641eeb995489ae0",
     "grade": true,
     "grade_id": "cell-77e007f13c53584d",
     "locked": true,
     "points": 7,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Do not consider this cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b64020-7fbd-4f40-a5e7-f3185b83ec5a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f464cc1f35ca60ab42ad78d49c70f054",
     "grade": true,
     "grade_id": "cell-505f63d6e9455065",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Do not consider this cell. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a294bd60",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a1f2209f00de5c6e6ded97df5c32e976",
     "grade": false,
     "grade_id": "cell-cd1b4519772911f1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Checkpoint\n",
    "\n",
    "This is just a check-point, i.e. it is for you to see that you are correctly implementing all functions. \n",
    "\n",
    "Execute the following code (just execute the next cell):\n",
    "```python\n",
    "master_sequence = generate_master_sequence(alphabet_size=4, seq_length=150, start_char=68)\n",
    "n_instances = 200\n",
    "n_outliers = n_instances//9\n",
    "n_inliners = n_instances - n_outliers\n",
    "seqs, targets = make_data(\n",
    "    master_sequence, \n",
    "    n_clusters=2,\n",
    "    cluster_centres_noise=.5,\n",
    "    n_inliners=n_inliners, \n",
    "    n_outliers=0, \n",
    "    inliner_noise=.15, \n",
    "    outlier_noise=.99, \n",
    "    endpoint_trim_dim=15)\n",
    "\n",
    "X = histogram_vectorizer(seqs)\n",
    "pca_plot(X, y=targets)\n",
    "```\n",
    "\n",
    "and check that you obtain a plot similar to:\n",
    "\n",
    "<img src=\"img0.png\" width=40%>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bd2f7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T17:09:22.508285Z",
     "start_time": "2024-04-10T17:09:22.258830Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "75745bac29df538924610466c5fafb4d",
     "grade": false,
     "grade_id": "cell-03197bf3956a4898",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "master_sequence = generate_master_sequence(alphabet_size=4, seq_length=150, start_char=68)\n",
    "n_instances = 200\n",
    "n_outliers = n_instances//9\n",
    "n_inliners = n_instances - n_outliers\n",
    "seqs, targets = make_data(\n",
    "    master_sequence, \n",
    "    n_clusters=2,\n",
    "    cluster_centres_noise=.5,\n",
    "    n_inliners=n_inliners, \n",
    "    n_outliers=0, \n",
    "    inliner_noise=.15, \n",
    "    outlier_noise=.99, \n",
    "    endpoint_trim_dim=15)\n",
    "\n",
    "X = histogram_vectorizer(seqs)\n",
    "pca_plot(X, y=targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046d6f45",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b6908cb08213b224f4e5d43b70a8d0a3",
     "grade": false,
     "grade_id": "cell-ff78c6bd090bab61",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 3\n",
    "\n",
    "<div style=\"text-align: right\"><b>[20 marks]</b></div>\n",
    "\n",
    "**Adaptive Boosting (AdaBoost) and Random Forest Classification**\n",
    "\n",
    "**Objective:**\n",
    "The objective of this section of the programming assignment is to implement two ensemble learning methods: Adaptive Boosting (AdaBoost) and Random Forest Classification. The candidate will implement functions for training and testing these ensemble models using decision tree classifiers. As an auxiliary process implement also a function for creating a bootstrapped replicate of a given dataset and extracting the out-of-bag (OOB) instances.\n",
    "\n",
    "**Functions to Implement:**\n",
    "\n",
    "1. `train_ab(X_train, y_train, param)`\n",
    "   - **Input:**\n",
    "     - `X_train`: Training feature matrix\n",
    "     - `y_train`: Training labels\n",
    "     - `param`: Maximum depth of decision trees used in the ensemble\n",
    "   - **Output:**\n",
    "     - List of tuples containing the learned models and their corresponding weights.\n",
    "   - **Description:**\n",
    "     - Trains an AdaBoost ensemble model using decision tree classifiers as base learners. The function iteratively updates the weights of the training instances based on their performance and combines multiple weak learners into a strong learner.\n",
    "\n",
    "2. `test_ab(X_test, models)`\n",
    "   - **Input:**\n",
    "     - `X_test`: Test feature matrix\n",
    "     - `models`: List of tuples containing the learned models and their corresponding weights obtained from `train_ab` function\n",
    "   - **Output:**\n",
    "     - Predicted labels for the test data.\n",
    "   - **Description:**\n",
    "     - Makes predictions on the test data using the trained AdaBoost ensemble model.\n",
    "\n",
    "3. **`AdaBoostClassifier` Class:**\n",
    "   - **Attributes:**\n",
    "     - `max_depth`: Maximum depth of decision trees to be used as base classifiers.\n",
    "     - `models`: List to store the trained AdaBoost models.\n",
    "   - **Methods:**\n",
    "     - `__init__(self, max_depth=1)`: Constructor method to initialize the AdaBoost classifier with a specified maximum depth.\n",
    "     - `fit(self, X, y)`: Method to train the AdaBoost classifier on the input training data `X` and labels `y`.\n",
    "     - `predict(self, X)`: Method to predict labels for the input data `X` using the trained AdaBoost classifier.\n",
    "   - **Description:**\n",
    "     - The `AdaBoostClassifier` class should use the previous functions `train_ab` and `test_ab`. \n",
    "     \n",
    "**Notes:**\n",
    "- You can use as weak learner the class `DecisionTreeClassifier` from `sklearn`.\n",
    "- You must provide your own implementation of the boosting algorithm i.e. you cannot use `AdaBoostClassifier` from `sklearn` in your code.\n",
    "- `param` is an integer representing the maximum depth of decision trees\n",
    "\n",
    "4. `make_bootstrap(data_matrix, targets)`\n",
    "   - **Input:**\n",
    "     - `data_matrix`: Input data matrix where each row represents an instance and each column represents a feature.\n",
    "     - `targets`: Target vector containing the labels corresponding to each instance in the data matrix.\n",
    "   - **Output:**\n",
    "     - `bootstrap_data_matrix`: Bootstrapped replicate of the input data matrix.\n",
    "     - `bootstrap_targets`: Bootstrapped replicate of the target vector.\n",
    "     - `bootstrap_sample_ids`: Vector containing the instance indices of the bootstrapped replicate of the data matrix.\n",
    "     - `oob_data_matrix`: Data matrix containing the out-of-bag instances.\n",
    "     - `oob_targets`: Target vector containing the labels of the out-of-bag instances.\n",
    "     - `oob_samples_ids`: Vector containing the instance indices of the out-of-bag instances.\n",
    "   - **Description:**\n",
    "     - Generates a bootstrapped replicate of the input dataset by sampling instances with replacement. The function then extracts the out-of-bag instances which are not included in the bootstrapped replicate.\n",
    "\n",
    "\n",
    "5. `train_rfc(X_train, y_train, param)`\n",
    "   - **Input:**\n",
    "     - `X_train`: Training feature matrix\n",
    "     - `y_train`: Training labels\n",
    "     - `param`: Maximum depth of decision trees used in the ensemble\n",
    "   - **Output:**\n",
    "     - List of trained decision tree classifiers representing the Random Forest ensemble.\n",
    "   - **Description:**\n",
    "     - Trains a Random Forest ensemble model using multiple decision tree classifiers. Each decision tree is trained on a bootstrapped sample of the training data.\n",
    "\n",
    "6. `test_rfc(X_test, models)`\n",
    "   - **Input:**\n",
    "     - `X_test`: Test feature matrix\n",
    "     - `models`: List of trained decision tree classifiers obtained from `train_rfc` function\n",
    "   - **Output:**\n",
    "     - Predicted labels for the test data.\n",
    "   - **Description:**\n",
    "     - Makes predictions on the test data using the trained Random Forest ensemble model.\n",
    "\n",
    "7. **`RandomForestClassifier` Class:**\n",
    "   - **Attributes:**\n",
    "     - `max_depth`: Maximum depth of decision trees to be used as base classifiers.\n",
    "     - `models`: List to store the trained decision tree models representing the Random Forest.\n",
    "   - **Methods:**\n",
    "     - `__init__(self, max_depth=1)`: Constructor method to initialize the Random Forest classifier with a specified maximum depth.\n",
    "     - `fit(self, X, y)`: Method to train the Random Forest classifier on the input training data `X` and labels `y`.\n",
    "     - `predict(self, X)`: Method to predict labels for the input data `X` using the trained Random Forest classifier.\n",
    "   - **Description:**\n",
    "     - The `RandomForestClassifier` class should use the previous functions `train_rfc` and `test_rfc`.\n",
    "\n",
    "**Notes:**\n",
    "- In your implementation of the Random Forest, you can use as decision tree the class `DecisionTreeClassifier` from `sklearn`.\n",
    "- You must provide your own implementation of the bagging algorithm i.e. you cannot use `RandomForestClassifier` from `sklearn` in your code.\n",
    "- `param` is an integer representing the maximum depth of decision trees\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a419ddc9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T17:09:22.556120Z",
     "start_time": "2024-04-10T17:09:22.510374Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "12ed9ebc22994729adbc372bfe2b7da5",
     "grade": false,
     "grade_id": "cell-47f850232ad07c54",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def train_ab(X_train, y_train, param):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def test_ab(X_test, models):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    \n",
    "class AdaBoostClassifier():\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    \n",
    "def make_bootstrap(data_matrix, targets):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "def train_rfc(X_train, y_train, param):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def test_rfc(X_test, models):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "class RandomForestClassifier():\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "save_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b0f7ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T17:09:22.623459Z",
     "start_time": "2024-04-10T17:09:22.558139Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e762713cd58873b493171734a3c12f0f",
     "grade": true,
     "grade_id": "cell-ddf00a5228fb9d27",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Do not consider this cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4220c9b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T17:09:22.631890Z",
     "start_time": "2024-04-10T17:09:22.625444Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a761808b4704dc8f91d9a30da7889d19",
     "grade": true,
     "grade_id": "cell-5f288555b633ac93",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Do not consider this cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc1aa8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T17:09:22.651274Z",
     "start_time": "2024-04-10T17:09:22.637832Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4089bc863860994ff40fcca11da19195",
     "grade": true,
     "grade_id": "cell-d10eb84c6ecc2c02",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Do not consider this cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f80adf4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T17:09:22.800334Z",
     "start_time": "2024-04-10T17:09:22.655120Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "46bba40a9508011a6fbd784677a4448a",
     "grade": true,
     "grade_id": "cell-8325b936cf4f8853",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Do not consider this cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27b18ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T17:09:22.804379Z",
     "start_time": "2024-04-10T17:09:22.802185Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e55dc8eb9be19e541762b4d7a785ca4f",
     "grade": true,
     "grade_id": "cell-cf660147dee48249",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Do not consider this cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4f116a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T17:09:22.808872Z",
     "start_time": "2024-04-10T17:09:22.806547Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "02060075688e4efd6db5f8bf819f1cba",
     "grade": true,
     "grade_id": "cell-7f69977dea6b2564",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Do not consider this cell. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf6d7ee",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d7f24ef35a53cc9ef12b7e9d70c87d15",
     "grade": false,
     "grade_id": "cell-f6f7fb3238677a61",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 4\n",
    "\n",
    "<div style=\"text-align: right\"><b>[10 marks]</b></div>\n",
    "\n",
    "\n",
    "**One-vs-One (OvO) Classification**\n",
    "\n",
    "\n",
    "**Objective:** The objective of this assignment is to implement a One-vs-One (OvO) classifier along with supporting functions for training and testing.\n",
    "\n",
    "**Functions to Implement:**\n",
    "\n",
    "1. `train_OvO(X_train, y_train, estimator)`\n",
    "   - **Inputs:**\n",
    "     - `X_train`: Feature matrix of shape `(n_samples, n_features)` representing the training data.\n",
    "     - `y_train`: Array of labels of shape `(n_samples,)` representing the training labels.\n",
    "     - `estimator`: The base estimator used for training the OvO classifier.\n",
    "   - **Output:**\n",
    "     - `estimators`: A dictionary containing the trained binary classifiers for each pair of classes.\n",
    "\n",
    "2. `test_OvO(X_test, estimators)`\n",
    "   - **Inputs:**\n",
    "     - `X_test`: Feature matrix of shape `(n_samples, n_features)` representing the test data.\n",
    "     - `estimators`: A dictionary containing the trained binary classifiers for each pair of classes.\n",
    "   - **Output:**\n",
    "     - `preds`: Predicted labels for the test data.\n",
    "\n",
    "3. `OVOClassifier` class\n",
    "   - **Attributes:**\n",
    "     - `estimator`: The base estimator to be used for training the OvO classifier.\n",
    "     - `estimators`: A dictionary containing the trained binary classifiers for each pair of classes.\n",
    "   - **Methods:**\n",
    "     - `__init__(self, estimator)`: Constructor method to initialize the OvO classifier with a specified base estimator.\n",
    "     - `fit(self, X, y)`: Method to train the OvO classifier on the input training data `X` and labels `y`.\n",
    "     - `predict(self, X)`: Method to predict labels for the input data `X` using the trained OvO classifier.\n",
    "\n",
    "**Requirements:**\n",
    "- The `train_OvO` function should train binary classifiers for all pairs of classes using the specified base estimator.\n",
    "- The `test_OvO` function should perform predictions using the trained binary classifiers for all pairs of classes and combine the results using majority voting.\n",
    "- The `OVOClassifier` class should provide a wrapper for training and testing the OvO classifier using the specified base estimator.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20c4dbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T17:09:22.869938Z",
     "start_time": "2024-04-10T17:09:22.810828Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9de2a0e986da43bc099de6d13a4b065c",
     "grade": false,
     "grade_id": "cell-d02e1178455b415c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import copy \n",
    "\n",
    "def train_OvO(X_train, y_train, estimator):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    \n",
    "def test_OvO(X_test, estimators):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    \n",
    "class OVOClassifier():\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "save_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362c831a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T17:09:25.333240Z",
     "start_time": "2024-04-10T17:09:22.872216Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8e60f5eb9fa360b74154751770e2fe76",
     "grade": true,
     "grade_id": "cell-f14d744f03e573d6",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Do not consider this cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8388d0dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T17:09:25.974933Z",
     "start_time": "2024-04-10T17:09:25.335478Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3fd67083b9919aba4841f307be3db8f8",
     "grade": true,
     "grade_id": "cell-44075ca8504b1004",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Do not consider this cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e086aa0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T17:09:26.607924Z",
     "start_time": "2024-04-10T17:09:25.976605Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eb6120bc199c51929ee1c6b35afda630",
     "grade": true,
     "grade_id": "cell-5d131fd7c2c6486a",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Do not consider this cell. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5548df76",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "856c452feed1fb2c827af499145a21b3",
     "grade": false,
     "grade_id": "cell-6623cd32fc9b05d9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 5\n",
    "\n",
    "<div style=\"text-align: right\"><b>[5 marks]</b></div>\n",
    "\n",
    "\n",
    "**Learning Curve Analysis**\n",
    "\n",
    "**Objective:**\n",
    "The objective of this assignment is to implement functions for analyzing learning curves in machine learning. The candidate will implement functions for computing learning curves and visualizing them using matplotlib.\n",
    "\n",
    "**Functions to Implement:**\n",
    "\n",
    "1. `compute_learning_curve(train_func, test_func, param, X, y, test_size, n_steps, n_repetitions)`\n",
    "   - **Input:**\n",
    "     - `train_func`: Function for training a machine learning model\n",
    "     - `test_func`: Function for testing a machine learning model\n",
    "     - `param`: Parameters for the training function\n",
    "     - `X`: Feature matrix\n",
    "     - `y`: Target labels\n",
    "     - `test_size`: Size of the test set (as a percentage of the dataset)\n",
    "     - `n_steps`: Number of steps for increasing the training set size\n",
    "     - `n_repetitions`: Number of repetitions for each step\n",
    "   - **Output:**\n",
    "     - `sizes`: Array containing the sizes of the training set used for each step\n",
    "     - `train_errors`: Array containing the mean training errors for each step\n",
    "     - `test_errors`: Array containing the mean test errors for each step\n",
    "   - **Description:**\n",
    "     - Computes the learning curves by repeatedly training the model on subsets of the training data with increasing sizes and evaluating performance on a fixed test set.\n",
    "     - the size for the smallest training set should be 1/10th of the size of the full training set. \n",
    "\n",
    "2. `plot_learning_curve(sizes, train_errors, test_errors)`\n",
    "   - **Input:**\n",
    "     - `sizes`: Array containing the sizes of the training set used for each step\n",
    "     - `train_errors`: Array containing the mean training errors for each step\n",
    "     - `test_errors`: Array containing the mean test errors for each step\n",
    "   - **Output:**\n",
    "     - A plot visualizing the learning curves\n",
    "   - **Description:**\n",
    "     - Plots the learning curves showing the mean training and test errors for different sizes of the training set.\n",
    "\n",
    "**Notes:**\n",
    "- Implement each function according to the given function signature and ensure correctness.\n",
    "\n",
    "\n",
    "The plot should produce something similar to:\n",
    "\n",
    "<img src=\"img3.png\" width=40%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8bd539",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T17:09:26.621136Z",
     "start_time": "2024-04-10T17:09:26.609453Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e25037e28eff4dfb025a76d2b44e8d68",
     "grade": false,
     "grade_id": "cell-c16f863b12743d0a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def compute_learning_curve(estimator, X, y, test_size, n_steps, n_repetitions):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    \n",
    "def plot_learning_curve(sizes, train_errors, test_errors):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "save_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbc7667",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T17:09:28.146659Z",
     "start_time": "2024-04-10T17:09:26.623248Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a97312790647e0fe909791105b8d4d8a",
     "grade": true,
     "grade_id": "cell-1e9d98da9b8d4770",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Do not consider this cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2839a271",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T17:14:52.502781Z",
     "start_time": "2024-04-10T17:14:52.367336Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fefc6931c9c991da2cb15a07a2781dbe",
     "grade": true,
     "grade_id": "cell-7ad51c320b39518c",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Do not consider this cell. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ae83c2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a38062e2cd06450e3f0906197e6370c7",
     "grade": false,
     "grade_id": "cell-800c41d15f1df578",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 6\n",
    "\n",
    "<div style=\"text-align: right\"><b>[15 marks]</b></div>\n",
    "\n",
    "**Sequence Kernel Methods and Multidimensional Scaling (MDS)**\n",
    "\n",
    "**Objective:**\n",
    "The objective of this assignment is to implement functions for computing kernel matrices using different sequence kernels and visualizing high-dimensional data in two dimensions using Multidimensional Scaling (MDS).\n",
    "\n",
    "**Functions to Implement:**\n",
    "\n",
    "1. `histogram_kernel(seq_1, seq_2, param=None)`\n",
    "   - **Input:**\n",
    "     - `seq_1`: First sequence (string)\n",
    "     - `seq_2`: Second sequence (string)\n",
    "     - `param`: Additional parameter (optional)\n",
    "   - **Output:**\n",
    "     - Kernel value computed using the histogram kernel between the input sequences.\n",
    "   - **Description:**\n",
    "     - Computes the kernel value using the histogram kernel between the input sequences. The histogram of a sequence is the count of how many times each symbol occurs in the sequence. The more similar the histograms are (i.e. if they contain similar values for the corresponding symbols) the higher should be the value computed by the kernel. The kernel should be normalised, i.e. the maximum value should be 1. The kernel value between two identical sequences should be 1.\n",
    "\n",
    "2. `kmer_kernel(seq_1, seq_2, param=None)`\n",
    "   - **Input:**\n",
    "     - `seq_1`: First sequence (string)\n",
    "     - `seq_2`: Second sequence (string)\n",
    "     - `param`: Additional parameter (e.g., length of k-mer, optional)\n",
    "   - **Output:**\n",
    "     - Kernel value computed using the k-mer kernel between the input sequences.\n",
    "   - **Description:**\n",
    "     - Computes the kernel value using the k-mer kernel between the input sequences. A k-mer is a contiguous sub-sequence. For example a sequence\" `ABCD` has the following 2-mers: `AB,BC,CD` and the following 3-mers: `ABC,BCD`. The k-mer kernel should return high values when the number of k-mers in common between two sequences is high.  The kernel should be normalised, i.e. the maximum value should be 1. The kernel value between two identical sequences should be 1. \n",
    "\n",
    "3. `get_gram_matrix(seqs, kernel_func, param)`\n",
    "   - **Input:**\n",
    "     - `seqs`: List of sequences (strings)\n",
    "     - `kernel_func`: Kernel function to compute pairwise kernel values\n",
    "     - `param`: Additional parameter required by the kernel function (optional)\n",
    "   - **Output:**\n",
    "     - Gram matrix computed using the specified kernel function and input sequences.\n",
    "   - **Description:**\n",
    "     - Computes the Gram matrix. The Gram matrix is the square matrix that contains the pairwise kernel values between the input sequences using the specified kernel function, i.e. in position (i,j) the Gram matrix contains the kernel between the i-th sequence  and the j-th sequence.\n",
    "\n",
    "4. `gram_matrix_to_distance_matrix(G)`\n",
    "   - **Input:**\n",
    "     - `G`: Gram matrix\n",
    "   - **Output:**\n",
    "     - Distance matrix computed from the Gram matrix.\n",
    "   - **Description:**\n",
    "     - Computes the distance matrix from the Gram matrix. The distance is inversely related to the similarity notion expressed in the Gram matrix, i.e. if similarity is 1 then distance is 0, if similarity is low then distance is high. \n",
    "\n",
    "5. `mds_plot(seqs, y=None, kernel_func=None, param=None)`\n",
    "   - **Input:**\n",
    "     - `seqs`: List of sequences (strings)\n",
    "     - `y`: Optional labels corresponding to each sequence for color-coding in the plot\n",
    "     - `kernel_func`: Kernel function to compute pairwise kernel values\n",
    "     - `param`: Additional parameter required by the kernel function (optional)\n",
    "   - **Output:**\n",
    "     - Visualization of high-dimensional data in two dimensions using multi-dimensional-scaling (MDS).\n",
    "   - **Description:**\n",
    "     - Computes the Gram matrix using the specified kernel function and input sequences, converts it into a distance matrix, and then applies MDS to visualize the data in two dimensions.\n",
    "\n",
    "**Notes:**\n",
    "- in `mds_plot` you may use the implementation of MDS offered by from `sklearn.manifold`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aced77c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T17:09:32.954786Z",
     "start_time": "2024-04-10T17:09:32.910196Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "21e505757342a884a35c5ee920763876",
     "grade": false,
     "grade_id": "cell-7ea68ca61ad94dfe",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def histogram_kernel(seq_1, seq_2, param=None):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def kmer_kernel(seq_1, seq_2, param=None):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def get_gram_matrix(seqs, kernel_func, param):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def gram_matrix_to_distance_matrix(G):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "\n",
    "from sklearn.manifold import MDS\n",
    "\n",
    "def mds_plot(seqs, y=None, kernel_func=None, param=None):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "save_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b495aa68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T17:09:32.958945Z",
     "start_time": "2024-04-10T17:09:32.956639Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9f882792e9431e426691dfb0e07df1ce",
     "grade": true,
     "grade_id": "cell-fde5a4db02ed7929",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Do not consider this cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bce9cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T17:09:32.963141Z",
     "start_time": "2024-04-10T17:09:32.960637Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "78e4d9e5f67e2f5781da63fc83763b17",
     "grade": true,
     "grade_id": "cell-a5d7b24c29fc5cc0",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Do not consider this cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddb51b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T17:09:32.966959Z",
     "start_time": "2024-04-10T17:09:32.964897Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "058645b64fd942b5e661d9eb48ea07d7",
     "grade": true,
     "grade_id": "cell-48841cab4f8666c0",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Do not consider this cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776c8672",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T17:09:32.970842Z",
     "start_time": "2024-04-10T17:09:32.968726Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "111db39f9264b03881ba4d656884634b",
     "grade": true,
     "grade_id": "cell-0246cb8b1e3717cc",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Do not consider this cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5599d1d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T17:09:32.974592Z",
     "start_time": "2024-04-10T17:09:32.972497Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "39dc8f4331c21076e3df827499123939",
     "grade": true,
     "grade_id": "cell-f9c0bd2d9e6fe99d",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Do not consider this cell. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccddadf",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "89ab6b26f1e89cff3801e3fe862dadd5",
     "grade": false,
     "grade_id": "cell-b26d40ea2b1e95e8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Checkpoint\n",
    "\n",
    "This is just a check-point, i.e. it is for you to see that you are correctly implementing all functions. \n",
    "\n",
    "Execute the following code (just execute the next cell):\n",
    "```python\n",
    "master_sequence = generate_master_sequence(alphabet_size=4, seq_length=150, start_char=68)\n",
    "n_instances = 200\n",
    "n_outliers = n_instances//9\n",
    "n_inliners = n_instances - n_outliers\n",
    "seqs, targets = make_data(\n",
    "    master_sequence, \n",
    "    n_clusters=2,\n",
    "    cluster_centres_noise=.5,\n",
    "    n_inliners=n_inliners, \n",
    "    n_outliers=0, \n",
    "    inliner_noise=.15, \n",
    "    outlier_noise=.99, \n",
    "    endpoint_trim_dim=15)\n",
    "\n",
    "mds_plot(seqs, y=targets, kernel_func=histogram_kernel, param=None)\n",
    "\n",
    "mds_plot(seqs, y=targets, kernel_func=kmer_kernel, param=3)\n",
    "```\n",
    "\n",
    "and check that you obtain a plot similar to:\n",
    "\n",
    "<img src=\"img1.png\" width=40%>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2108bce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T17:09:56.559051Z",
     "start_time": "2024-04-10T17:09:32.976348Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a14bf0db135cecc095fe6ad66a21a1fe",
     "grade": false,
     "grade_id": "cell-ea8eda029e2441f8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "master_sequence = generate_master_sequence(alphabet_size=4, seq_length=150, start_char=68)\n",
    "n_instances = 200\n",
    "n_outliers = n_instances//9\n",
    "n_inliners = n_instances - n_outliers\n",
    "seqs, targets = make_data(\n",
    "    master_sequence, \n",
    "    n_clusters=2,\n",
    "    cluster_centres_noise=.5,\n",
    "    n_inliners=n_inliners, \n",
    "    n_outliers=0, \n",
    "    inliner_noise=.15, \n",
    "    outlier_noise=.99, \n",
    "    endpoint_trim_dim=15)\n",
    "\n",
    "mds_plot(seqs, y=targets, kernel_func=histogram_kernel, param=None)\n",
    "\n",
    "mds_plot(seqs, y=targets, kernel_func=kmer_kernel, param=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963f8437",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "edf7d79e6aa3ebf079f964f6e48c4660",
     "grade": false,
     "grade_id": "cell-4bacd6c8dbfc612a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Kernelized Large Margin Classifiers\n",
    "\n",
    "In this exercise you are asked to develop the code to solve the optimization problem that defines a kernelized Large Margin Classifier with soft margins. \n",
    "\n",
    "### Linear case\n",
    "\n",
    "We need to match the solver's API which, according to the documentation is of the form:\n",
    "\n",
    "\\begin{aligned}\n",
    "    & \\min \\frac{1}{2} x^TPx + q^Tx\n",
    "    \\\\\n",
    "     s.t. \\ & \\ Gx \\leq h \n",
    "    \\\\\n",
    "    & \\ Ax = b\n",
    "\\end{aligned}\n",
    "\n",
    "Recall that the dual problem is expressed as:\n",
    "\n",
    "\\begin{aligned}\n",
    "\\max_{\\alpha} \\sum_i^m \\alpha_i - \\frac{1}{2} \\sum_{i,j}^m y^{(i)}y^{(j)} \\alpha_i \\alpha_j <x^{(i)}, x^{(j)}>\n",
    "\\end{aligned}\n",
    "\n",
    "Let $\\mathbf{H}$ be a matrix such that $H_{i,j} = y^{(i)}y^{(j)} <x^{(i)} x^{(j)}>$, then the optimization becomes:\n",
    "\n",
    "\\begin{aligned}\n",
    "    & \\max_{\\alpha} \\sum_i^m \\alpha_i  - \\frac{1}{2}  \\alpha^T \\mathbf{H}  \\alpha\n",
    "    \\\\\n",
    "     s.t. & \\ \\alpha_i \\geq 0 \n",
    "    \\\\\n",
    "    &  \\ \\sum_i^m \\alpha_i y^{(i)} = 0  \n",
    "\\end{aligned}\n",
    "\n",
    "We convert the sums into vector form and multiply both the objective and the constraint by −1 which turns this into a minimization problem and reverses the inequality\n",
    "\n",
    "\\begin{aligned}\n",
    "    & \\min_{\\alpha}  \\frac{1}{2}  \\alpha^T \\mathbf{H}  \\alpha - 1^T \\alpha\n",
    "    \\\\\n",
    "    & s.t. \\ - \\alpha_i \\leq 0 \n",
    "    \\\\\n",
    "    & s.t. \\ y^T \\alpha = 0 \n",
    "\\end{aligned}\n",
    "\n",
    "We are now ready to convert our numpy arrays into the cvxopt format, using the same notation as in the documentation this gives\n",
    "\n",
    "* $P:=H$ a matrix of size $m×m$\n",
    "* $q:=−\\vec{1}$  a vector of size $m×1$\n",
    "* $G:=−diag[1]$ a diagonal matrix of -1s of size $m×m$\n",
    "* $h:=\\vec{0}$ a vector of zeros of size $m×1$\n",
    "* $A:=y^T$ the label vector of size $1×m$\n",
    "* $b:=0$ a scalar\n",
    "\n",
    "Note that in the simple example of $m=2$ the matrix $G$ and vector $h$ which define the constraint are \n",
    "\n",
    "$$G = \\begin{bmatrix} -1 & 0 \\\\ 0 & -1 \\end{bmatrix} \\ \\ \\text{and} \\ \\ h = \\begin{bmatrix} 0 \\\\ 0  \\end{bmatrix}$$\n",
    "\n",
    "### Computing the matrix $\\mathbf{H}$ in vectorized form\n",
    "\n",
    "Consider the simple example with 2 input samples $\\{x^{(1)}, x^{(2)}\\} \\in \\mathbb{R}^2$ which are two dimensional vectors. i.e. $x^{(1)} = (x_1^{(1)} , x_2^{(1)})^T$\n",
    "\n",
    "$$X = \\begin{bmatrix} x_1^{(1)} & x_2^{(1)} \\\\ x_1^{(2)} & x_2^{(2)} \\end{bmatrix} \\ \\ \\text{and} \\ \\ y = \\begin{bmatrix} y^{(1)}  \\\\ y^{(2)} \\end{bmatrix}$$\n",
    "\n",
    "We now proceed to creating a new matrix $X′$ where each input sample $x$ is multiplied by the corresponding output label y. This can be done easily in Numpy using vectorization and padding.\n",
    "\n",
    "$$X' = \\begin{bmatrix} x^{(1)}_1 y^{(1)} & x^{(1)}_2y^{(1)} \\\\\n",
    "x^{(2)}_1y^{(2)} & x^{(2)}_2y^{(2)} \\end{bmatrix}$$\n",
    "\n",
    "Finally we take the **matrix multiplication** of $X′$ and its transpose giving $H=X′X′^T$\n",
    "\n",
    "$$H = X' @ X'^T = \\begin{bmatrix} x^{(1)}_1 y^{(1)} & x^{(1)}_2y^{(1)} \\\\\n",
    "x^{(2)}_1y^{(2)} & x^{(2)}_2y^{(2)} \\end{bmatrix} \\begin{bmatrix} x^{(1)}_1 y^{(1)} & x^{(2)}_1 y^{(2)}  \\\\\n",
    "x^{(1)}_2y^{(1)} & x^{(2)}_2y^{(2)} \\end{bmatrix}$$\n",
    "\n",
    "$$H = \\begin{bmatrix}  x^{(1)}_1 x^{(1)}_1y^{(1)}y^{(1)} + x^{(1)}_2x^{(1)}_2y^{(1)}y^{(1)} & x^{(1)}_1 x^{(2)}_1y^{(1)}y^{(2)} + x^{(1)}_2x^{(2)}_2y^{(1)}y^{(2)} \\\\ x^{(2)}_1 x^{(1)}_1y^{(2)}y^{(1)} + x^{(2)}_2x^{(1)}_2y^{(2)}y^{(1)} & x^{(2)}_1 x^{(2)}_1y^{(2)}y^{(2)} + x^{(2)}_2x^{(2)}_2y^{(2)}y^{(2)} \\end{bmatrix}$$\n",
    "\n",
    "\n",
    "### Soft margin\n",
    "For the softmax margin SVM, recall that the optimization problem can be expressed as\n",
    "\n",
    "\\begin{aligned}\n",
    "    & \\max_{\\alpha} \\sum_i^m \\alpha_i  - \\frac{1}{2}  \\alpha^T \\mathbf{H}  \\alpha\n",
    "    \\\\\n",
    "     s.t. \\ \\ & 0 \\leq \\alpha_i \\leq C \n",
    "    \\\\\n",
    "    &  \\ \\sum_i^m \\alpha_i y^{(i)} = 0  \n",
    "\\end{aligned}\n",
    "\n",
    "which can be written in standard form as\n",
    "\n",
    "\\begin{aligned}\n",
    "    & \\min_{\\alpha}  \\frac{1}{2}  \\alpha^T \\mathbf{H}  \\alpha - 1^T \\alpha\n",
    "    \\\\\n",
    "     s.t. & \\ - \\alpha_i \\leq 0 \n",
    "    \\\\\n",
    "     & \\alpha_i \\leq C\n",
    "     \\\\\n",
    "     &\\ y^T \\alpha = 0  \n",
    "\\end{aligned}\n",
    "\n",
    "This is almost the same problem as previously, except for the additional inequality constraint on $\\alpha$. We translate this new constraint into standard form by concatenating below matrix $G$ a diagonal matrix of 1s of size $m \\times m$. Similarly for the vector $h$ to which the value of $C$ is added $m$ times.\n",
    "\n",
    "Note that in the simple example of $m=2$ the matrix $G$ and vector $h$ which define the constraint are\n",
    "\n",
    "$$G = \\begin{bmatrix} -1 & 0 \\\\ 0 & -1 \\\\ 1 & 0 \\\\ 0 & 1\\end{bmatrix} \\ \\ \\text{and} \\ \\ h = \\begin{bmatrix} 0 \\\\ 0 \\\\ C \\\\ C \\end{bmatrix}$$\n",
    "\n",
    "\n",
    "### Non linear case\n",
    "\n",
    "What has been written above corresponds to the hard and the soft margin case for a linear large margin classification problem.  \n",
    "\n",
    "You now need to appy the *kernel trick*, i.e. you need to replace the dot product operations in the input space $<x^{(i)} x^{(j)}>$ with the dot product in the feature space via a kernel function $K(x^{(i)},x^{(j)}) = <\\phi(x^{(i)}) \\phi(x^{(j)})>$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdb77a7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c66703ac94a7b83d5f819bd463ac650f",
     "grade": false,
     "grade_id": "cell-8bdc3e5af74a2268",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 7\n",
    "\n",
    "<div style=\"text-align: right\"><b>[25 marks]</b></div>\n",
    "\n",
    "**Soft Large Margin Kernel Classifier**\n",
    "\n",
    "**Objective:**\n",
    "The objective of this assignment is to implement a Soft Large Margin Kernel Classifier (SLMKC) using convex optimization techniques. The SLMKC is a binary classifier that learns decision boundaries by maximizing the margin between classes while allowing for some misclassifications.\n",
    "\n",
    "**Functions to Implement:**\n",
    "\n",
    "1. `make_H_k(X, t, kernel_function, param)`\n",
    "   - **Input:**\n",
    "     - `X`: Input feature matrix (numpy array or pandas DataFrame).\n",
    "     - `t`: Target vector (numpy array or pandas Series) containing the class labels (-1 or 1).\n",
    "     - `kernel_function`: Kernel function used for computing the Gram matrix.\n",
    "     - `param`: Parameter(s) required by the kernel function.\n",
    "   - **Output:**\n",
    "     - Gram matrix H computed using the kernel function.\n",
    "   - **Description:**\n",
    "     - Computes the Gram matrix H required for setting up the optimization problem.\n",
    "\n",
    "2. `setup_optimization_soft_k(X, t, C, kernel_function, param)`\n",
    "   - **Input:**\n",
    "     - `X`: Input feature matrix (numpy array or pandas DataFrame).\n",
    "     - `t`: Target vector (numpy array or pandas Series) containing the class labels (-1 or 1).\n",
    "     - `C`: Regularization parameter.\n",
    "     - `kernel_function`: Kernel function used for computing the Gram matrix.\n",
    "     - `param`: Parameter(s) required by the kernel function.\n",
    "   - **Output:**\n",
    "     - Matrices and vectors required for the optimization problem.\n",
    "   - **Description:**\n",
    "     - Make the function `P, q, G, h, A, b = setup_optimization_soft_k(X, t, C, kernel_function, param)` to compute the necessary matrices to solve the QP problem associated to the soft margin kernelized classification task using the library [cvxopt](http://cvxopt.org/). The function receives in input a data matrix `X`, an associated target vector `t`, a regularization parameter `C` and a kernel function `kernel_function` with parameter `param`. \n",
    "\n",
    "3. `compute_support_vectors(X, t, alphas)`\n",
    "   - **Input:**\n",
    "     - `X`: Input feature matrix (numpy array or pandas DataFrame).\n",
    "     - `t`: Target vector (numpy array or pandas Series) containing the class labels (-1 or 1).\n",
    "     - `alphas`: Array of Lagrange multipliers obtained from the optimization.\n",
    "   - **Output:**\n",
    "     - Lists containing the support vectors, their corresponding targets, alphas, and indices.\n",
    "   - **Description:**\n",
    "\n",
    "Make the function `support_vectors, support_targets, support_alphas, support_ids = compute_support_vectors(X,t,alphas)`  to compute:\n",
    "- `support_vectors` the support vectors\n",
    "- `support_targets` the target vector associated to the support vectors\n",
    "- `support_alphas` the vector of the dual variables $\\alpha_i$ associated to the support vectors\n",
    "- `support_ids` a boolean vector that indicates if a position is associated to a support vector (w.r.t. the original data matrix) (i.e. if the first instance is a support vector and the second one it is not, then `support_ids` = [True, False])\n",
    "\n",
    "4. `train_slmkc(X, t, C, kernel_function, param)`\n",
    "   - **Input:**\n",
    "     - `X`: Input feature matrix (numpy array or pandas DataFrame).\n",
    "     - `t`: Target vector (numpy array or pandas Series) containing the class labels (-1 or 1).\n",
    "     - `C`: Regularization parameter.\n",
    "     - `kernel_function`: Kernel function used for computing the Gram matrix.\n",
    "     - `param`: Parameter(s) required by the kernel function.\n",
    "   - **Output:**\n",
    "     - Lists containing the support vectors, their corresponding targets, alphas, and indices.\n",
    "   - **Description:**\n",
    "Make the function `model = train_slmkc(X, t, C, kernel_function, param)` to compute the necessary elements to represent a kernelized soft large margin classifier trained over an input data matrix `X` with an associated target vector `t`, for a regularization parameter `C` and a kernel function `kernel_function` with parameter `param`. \n",
    "\n",
    "Note: you may implement `model` as a tuple containing information on the support vectors and the dual variables, i.e. `model = (support_vectors,support_targets,support_alphas, support_ids)`.\n",
    "\n",
    "5. `compute_bias(kernel_function, param, C, model)`\n",
    "   - **Input:**\n",
    "     - `kernel_function`: Kernel function used for computing the Gram matrix.\n",
    "     - `param`: Parameter(s) required by the kernel function.\n",
    "     - `C`: Regularization parameter.\n",
    "     - `model`: Trained model obtained from `train_slmkc`.\n",
    "   - **Output:**\n",
    "     - Bias term computed based on the support vectors.\n",
    "   - **Description:**\n",
    "     - Computes the bias term required for making predictions.\n",
    "\n",
    "Given the kernelized soft large margin discriminant function of the form:\n",
    "$$ y(x) = \\sum_{n \\in SV} \\alpha_n t_n K(x_n,x) + b $$\n",
    "\n",
    "and given the encoded `model` to represent the necessary elements for a trained kernelized soft large margin classifier\n",
    "\n",
    "make the function `b = compute_bias(kernel_function, param, C, model)` to compute the offset/bias term `b`,  for a regularization parameter `C` and a kernel function `kernel_function` with parameter `param`. \n",
    "\n",
    "6. `score_slmkc(X_test, kernel_function, param, C, model)`\n",
    "   - **Input:**\n",
    "     - `X_test`: Test feature matrix (numpy array or pandas DataFrame).\n",
    "     - `kernel_function`: Kernel function used for computing the Gram matrix.\n",
    "     - `param`: Parameter(s) required by the kernel function.\n",
    "     - `C`: Regularization parameter.\n",
    "     - `model`: Trained model obtained from `train_slmkc`.\n",
    "   - **Output:**\n",
    "     - Predicted scores for the test instances.\n",
    "   - **Description:**\n",
    "     - Computes the decision scores for the test instances using the trained model.\n",
    "\n",
    "7. `test_slmkc(X_test, kernel_function, param, C, model)`\n",
    "   - **Input:**\n",
    "     - `X_test`: Test feature matrix (numpy array or pandas DataFrame).\n",
    "     - `kernel_function`: Kernel function used for computing the Gram matrix.\n",
    "     - `param`: Parameter(s) required by the kernel function.\n",
    "     - `C`: Regularization parameter.\n",
    "     - `model`: Trained model obtained from `train_slmkc`.\n",
    "   - **Output:**\n",
    "     - Predicted class labels for the test instances.\n",
    "   - **Description:**\n",
    "     - Makes predictions on the test instances using the trained model.\n",
    "\n",
    "\n",
    "8. `SoftLargeMarginKernelClassifier` class\n",
    "   - **Attributes:**\n",
    "     - `C`: Regularization parameter.\n",
    "     - `kernel_function`: Function that computes the kernel between two vectors.\n",
    "     - `param`: Additional parameters needed for the kernel function.\n",
    "     - `support_vectors`: Support vectors obtained from the training data.\n",
    "     - `support_targets`: Target labels corresponding to the support vectors.\n",
    "     - `support_alphas`: Alpha values associated with the support vectors.\n",
    "     - `support_ids`: Indices of the support vectors in the original training data.\n",
    "   - **Methods:**\n",
    "     - `__init__(self, C, kernel_function, param)`: Constructor method to initialize the Soft Large Margin Kernel Classifier with specified parameters.\n",
    "     - `fit(self, X, y)`: Method to train the classifier on the input training data `X` and labels `y`.\n",
    "     - `predict(self, X)`: Method to predict labels for the input data `X` using the trained classifier.\n",
    "     - `decision_function(self, X)`: Method to compute the decision function values for the input data `X`.\n",
    "     - `predict_proba(self, X)`: Method to compute class probabilities for the input data `X`.\n",
    "\n",
    "   - **Description:**\n",
    "     - A class wrapper for the Soft Large Margin Kernel Classifier providing methods for fitting the model to training data, making predictions, computing decision scores, and predicting class probabilities.\n",
    "\n",
    "\n",
    "**Note:** \n",
    "- The SVM classifier is defined for binary classification problems with targets 1 for the positive class and -1 for the negative class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7187d86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T17:09:56.584608Z",
     "start_time": "2024-04-10T17:09:56.561155Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4cd893aa2e97573f978a521faf38d227",
     "grade": false,
     "grade_id": "cell-0c0ea07a548b484c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from cvxopt import matrix\n",
    "from cvxopt import solvers\n",
    "\n",
    "def make_H_k(X,t, kernel_function, param):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "def setup_optimization_soft_k(X,t,C, kernel_function, param):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "def compute_support_vectors(X,t,alphas):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "def train_slmkc(X, t, C, kernel_function, param):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "def compute_bias(kernel_function, param, C, model):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "def score_slmkc(X_test, kernel_function, param, C, model):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "def test_slmkc(X_test, kernel_function, param, C, model):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "class SoftLargeMarginKernelClassifier(object):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "save_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4086df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T17:10:13.075356Z",
     "start_time": "2024-04-10T17:10:13.069890Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4db7f36026c500b5b0183a48c42c4a89",
     "grade": true,
     "grade_id": "cell-76dd68be871cc7f7",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Do not consider this cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92472166",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T17:10:18.898769Z",
     "start_time": "2024-04-10T17:10:18.891178Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b8fa4e5b0a4a87fc10ba42c8dcafe406",
     "grade": true,
     "grade_id": "cell-7ca19940a60cdc77",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Do not consider this cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65926aa8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T17:10:24.648590Z",
     "start_time": "2024-04-10T17:10:24.642846Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9c0b0ec2be2c1e82c05b10919ced626d",
     "grade": true,
     "grade_id": "cell-3b694b8110b4664a",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Do not consider this cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f898f638",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T17:10:28.916378Z",
     "start_time": "2024-04-10T17:10:28.886466Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "afbc4e0b2a19ad0fbb95262a31882228",
     "grade": true,
     "grade_id": "cell-9d2efae2c7f273ab",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Do not consider this cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d496eff4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T17:10:33.010227Z",
     "start_time": "2024-04-10T17:10:33.002942Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ccc3cd9b183b3cf2b824f3892132ef97",
     "grade": true,
     "grade_id": "cell-c195c7fe9d56f751",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Do not consider this cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8002c32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T17:10:37.109109Z",
     "start_time": "2024-04-10T17:10:37.101797Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f9ac660859313570185af4be1a761a36",
     "grade": true,
     "grade_id": "cell-1a65565f984c9e39",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Do not consider this cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d357de2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T17:10:40.727071Z",
     "start_time": "2024-04-10T17:10:40.719087Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3de72dcc8c70b9bd05856fc9e9210cfc",
     "grade": true,
     "grade_id": "cell-0ce790e675186097",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Do not consider this cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb23b21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T17:10:47.422912Z",
     "start_time": "2024-04-10T17:10:47.414218Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d07f624a65c6984f809f05b77d79202f",
     "grade": true,
     "grade_id": "cell-b7fcdf49e06c4a2c",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Do not consider this cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c405d57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T17:10:52.337002Z",
     "start_time": "2024-04-10T17:10:52.328842Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4ea2b923dd0fe4afa8ee8b0146a1c705",
     "grade": true,
     "grade_id": "cell-3ad3dcdd0a58a3b5",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Do not consider this cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad50f8cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T17:11:01.366910Z",
     "start_time": "2024-04-10T17:11:01.364226Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "50969210f7afe25bc2db890e72f9329c",
     "grade": true,
     "grade_id": "cell-aa378c97b1332689",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Do not consider this cell. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a986aa8e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2516fd9177ddcf7ca9f35c68031c49b3",
     "grade": false,
     "grade_id": "cell-c6e7d6838c1b7096",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 8\n",
    "\n",
    "<div style=\"text-align: right\"><b>[5 marks]</b></div>\n",
    "\n",
    "**2D Sequence Plotting**\n",
    "\n",
    "**Objective:**\n",
    "The objective of this assignment is to implement a function for visualizing sequences in a 2-dimensional space using Multi-Dimensional Scaling (MDS). The function should allow for visualization of sequences along with optional additional features such as true labels, predicted labels, and support vectors.\n",
    "\n",
    "**Function to Implement:**\n",
    "\n",
    "1. `plot_seq_2d(seqs, y=None, preds=None, is_support=None, kernel_func=None, param=None)`\n",
    "   - **Input:**\n",
    "     - `seqs`: List of sequences to be plotted.\n",
    "     - `y`: True labels corresponding to the sequences (optional).\n",
    "     - `preds`: Predicted labels corresponding to the sequences (optional).\n",
    "     - `is_support`: Boolean array indicating whether a sequence is a support vector (optional).\n",
    "     - `kernel_func`: Kernel function used for computing the Gram matrix (optional).\n",
    "     - `param`: Parameter(s) required by the kernel function (optional).\n",
    "   - **Output:**\n",
    "     - None\n",
    "   - **Description:**\n",
    "     - Visualizes the sequences in a 2-dimensional space using Multi-Dimensional Scaling (MDS).\n",
    "     - Optionally, displays true labels (`y`), predicted labels (`preds`), and support vectors (`is_support`).\n",
    "     - Points representing sequences are colored based on the true labels (`y`).\n",
    "     - If `preds` and `y` are provided, misclassified instances are highlighted with 'X' markers.\n",
    "     - If `is_support` is provided, support vectors are indicated with smaller points with a black border.\n",
    "\n",
    "**Additional Notes:**\n",
    "- The function should utilize the provided `get_gram_matrix` and `gram_matrix_to_distance_matrix` functions to compute the Gram matrix and distance matrix, respectively.\n",
    "- Ensure the visualization is clear and informative, with appropriate labeling and coloring of data points.\n",
    "- See the Checkpoint for an example of what the output should look like.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329ef236",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T17:11:01.384581Z",
     "start_time": "2024-04-10T17:11:01.369882Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "20cc103e4f1aa803eb46e076043395dd",
     "grade": false,
     "grade_id": "cell-777470b652a81a36",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import MDS\n",
    "\n",
    "def plot_seq_2d(seqs, y=None, preds=None, is_support=None, kernel_func=None, param=None):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "save_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f4e028",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T17:11:01.389150Z",
     "start_time": "2024-04-10T17:11:01.386565Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "727738368bb702b495e3ab04be31e68c",
     "grade": true,
     "grade_id": "cell-c39e2fc234fd197f",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Do not consider this cell. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32e050c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "22bbad7da95a017e5825bc2045e8537f",
     "grade": false,
     "grade_id": "cell-ffcea73a3da67e26",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Checkpoint\n",
    "\n",
    "This is just a check-point, i.e. it is for you to see that you are correctly implementing all functions. \n",
    "\n",
    "Execute the following code (just execute the next cell):\n",
    "```python\n",
    "master_sequence = generate_master_sequence(alphabet_size=5, seq_length=30, start_char=68)\n",
    "n_instances = 200\n",
    "n_outliers = n_instances//5\n",
    "n_inliners = n_instances - n_outliers\n",
    "seqs, targets = make_data(\n",
    "    master_sequence, \n",
    "    n_clusters=2,\n",
    "    cluster_centres_noise=.3,\n",
    "    n_inliners=n_inliners, \n",
    "    n_outliers=n_outliers, \n",
    "    inliner_noise=.15, \n",
    "    outlier_noise=.99, \n",
    "    endpoint_trim_dim=5)\n",
    "\n",
    "param = 3\n",
    "y = np.array(targets)\n",
    "y[y==0]=-1\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_seqs, test_seqs, train_y, test_y = train_test_split(seqs,y, train_size=.5)\n",
    "\n",
    "est = SoftLargeMarginKernelClassifier(C=1e0, kernel_function=kmer_kernel, param=param)\n",
    "est.fit(train_seqs, train_y)\n",
    "\n",
    "preds = est.predict(train_seqs)\n",
    "plot_seq_2d(train_seqs, y=train_y, preds=preds, is_support=est.support_ids, kernel_func=kmer_kernel, param=param)\n",
    "\n",
    "preds = est.predict(test_seqs)\n",
    "plot_seq_2d(test_seqs, y=test_y, preds=preds, kernel_func=kmer_kernel, param=param)\n",
    "```\n",
    "\n",
    "and check that you obtain a plot similar to:\n",
    "\n",
    "<img src=\"img2.png\" width=40%>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac62a9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T17:11:11.889076Z",
     "start_time": "2024-04-10T17:11:01.392336Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "31d30505992796cef419d598b91c76c1",
     "grade": false,
     "grade_id": "cell-3d20339ef208f1df",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "master_sequence = generate_master_sequence(alphabet_size=5, seq_length=30, start_char=68)\n",
    "n_instances = 200\n",
    "n_outliers = n_instances//5\n",
    "n_inliners = n_instances - n_outliers\n",
    "seqs, targets = make_data(\n",
    "    master_sequence, \n",
    "    n_clusters=2,\n",
    "    cluster_centres_noise=.3,\n",
    "    n_inliners=n_inliners, \n",
    "    n_outliers=n_outliers, \n",
    "    inliner_noise=.15, \n",
    "    outlier_noise=.99, \n",
    "    endpoint_trim_dim=5)\n",
    "\n",
    "param = 3\n",
    "y = np.array(targets)\n",
    "y[y==0]=-1\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_seqs, test_seqs, train_y, test_y = train_test_split(seqs,y, train_size=.5)\n",
    "\n",
    "est = SoftLargeMarginKernelClassifier(C=1e0, kernel_function=kmer_kernel, param=param)\n",
    "est.fit(train_seqs, train_y)\n",
    "\n",
    "preds = est.predict(train_seqs)\n",
    "plot_seq_2d(train_seqs, y=train_y, preds=preds, is_support=est.support_ids, kernel_func=kmer_kernel, param=param)\n",
    "\n",
    "preds = est.predict(test_seqs)\n",
    "plot_seq_2d(test_seqs, y=test_y, preds=preds, kernel_func=kmer_kernel, param=param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45971445-b231-4fe1-b748-f603304b2f7f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3b64ffbc836b6c68a09b80d37279bf89",
     "grade": false,
     "grade_id": "cell-e84b7977bf88331c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Checkpoint\n",
    "\n",
    "This is just a check-point, i.e. it is for you to see that you are correctly implementing all functions. \n",
    "\n",
    "Execute the following code (just execute the next cell):\n",
    "```python\n",
    "master_sequence = generate_master_sequence(alphabet_size=5, seq_length=30, start_char=68)\n",
    "n_instances = 100\n",
    "n_outliers = n_instances//5\n",
    "n_inliners = n_instances - n_outliers\n",
    "seqs, targets = make_data(\n",
    "    master_sequence, \n",
    "    n_clusters=3,\n",
    "    cluster_centres_noise=.3,\n",
    "    n_inliners=n_inliners, \n",
    "    n_outliers=n_outliers, \n",
    "    inliner_noise=.15, \n",
    "    outlier_noise=.99, \n",
    "    endpoint_trim_dim=5)\n",
    "\n",
    "mds_plot(seqs, y=targets, kernel_func=kmer_kernel, param=3)\n",
    "\n",
    "seqs_train, seqs_test, targets_train, targets_test = train_test_split(seqs, targets, test_size=0.33, shuffle=True, random_state=0)\n",
    "estimator = SoftLargeMarginKernelClassifier(C=1e0, kernel_function=kmer_kernel, param=3)\n",
    "est = OVOClassifier(estimator=estimator)\n",
    "est.fit(seqs_train, targets_train)\n",
    "preds = est.predict(seqs_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(targets_test, preds)\n",
    "print('Predictive accuracy: %.2f'%acc)\n",
    "```\n",
    "\n",
    "and check that you obtain a plot similar to:\n",
    "\n",
    "<img src=\"img4.png\" width=40%>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4bc867-c9c7-4954-9dec-cb8953375e04",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "71ee9fe919423625fb8936748d924f55",
     "grade": false,
     "grade_id": "cell-40b544d59d1cfff4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "master_sequence = generate_master_sequence(alphabet_size=5, seq_length=30, start_char=68)\n",
    "n_instances = 100\n",
    "n_outliers = n_instances//5\n",
    "n_inliners = n_instances - n_outliers\n",
    "seqs, targets = make_data(\n",
    "    master_sequence, \n",
    "    n_clusters=3,\n",
    "    cluster_centres_noise=.3,\n",
    "    n_inliners=n_inliners, \n",
    "    n_outliers=n_outliers, \n",
    "    inliner_noise=.15, \n",
    "    outlier_noise=.99, \n",
    "    endpoint_trim_dim=5)\n",
    "\n",
    "mds_plot(seqs, y=targets, kernel_func=kmer_kernel, param=3)\n",
    "\n",
    "seqs_train, seqs_test, targets_train, targets_test = train_test_split(seqs, targets, test_size=0.33, shuffle=True, random_state=0)\n",
    "estimator = SoftLargeMarginKernelClassifier(C=1e0, kernel_function=kmer_kernel, param=3)\n",
    "est = OVOClassifier(estimator=estimator)\n",
    "est.fit(seqs_train, targets_train)\n",
    "preds = est.predict(seqs_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(targets_test, preds)\n",
    "print('Predictive accuracy: %.2f'%acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59119fab",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5d6ec69f6b5a946acc69dd5c5125b6e6",
     "grade": false,
     "grade_id": "cell-322b7567300498a9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e282e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T17:11:11.893089Z",
     "start_time": "2024-04-10T17:11:11.891029Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b6bd0fcd4414879031fd1887b782efec",
     "grade": false,
     "grade_id": "cell-d46c8e359c69f649",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Do not consider the next cell.\n",
    "# You do not have to do anything for the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2cce35",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6e02cfbe1bac16843d6cbc285747f9a1",
     "grade": false,
     "grade_id": "cell-070381afd0ce6008",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db84127f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T17:11:11.974073Z",
     "start_time": "2024-04-10T17:11:11.895182Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ad306b877702e9a4491662298a0ac8c3",
     "grade": false,
     "grade_id": "cell-86fdbce1b5610028",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "check_and_prepare_for_submission()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6faf9181",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "aa0a358652a0397babb9b56885432109",
     "grade": false,
     "grade_id": "cell-9a46175997b3baa9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
