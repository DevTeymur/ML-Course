2024-04-23-21-12-19 392 1 from cvxopt import matrix	from cvxopt import solvers		def make_H_k(X,t, kernel_function, param):	    n_samples = len(X)	    H = np.zeros((n_samples, n_samples))	    for i in range(n_samples):	        for j in range(n_samples):	            H[i, j] = t[i] * t[j] * kernel_function(X[i], X[j], param)	    return H	    	def setup_optimization_soft_k(X,t,C, kernel_function, param):	    n_samples = len(X)	    H = make_H_k(X, t, kernel_function, param)	    P = matrix(H, tc='d')	    q = matrix(-1.0, (n_samples, 1))	    G = matrix(np.diag(-1.0 * np.ones(n_samples)), tc='d')	    h = matrix(np.zeros(n_samples))	    A = matrix(t.reshape(1, -1), tc='d')	    b = matrix(0.0)	    return P, q, G, h, A, b	    	def compute_support_vectors(X,t,alphas, tolerance=1e-5):	    sv_idx = alphas > tolerance	    return X[sv_idx], t[sv_idx], alphas[sv_idx], sv_idx	    	def train_slmkc(X, t, C, kernel_function, param):	    n_samples = len(X)	    P, q, G, h, A, b = setup_optimization_soft_k(X, t, C, kernel_function, param)	    sol = solvers.qp(P, q, G, h, A, b)	    alphas = np.array(sol['x']).flatten()	    return compute_support_vectors(X, t, alphas)	    	def compute_bias(kernel_function, param, C, model):	    support_vectors, support_targets, support_alphas, _ = model	    bias = np.mean(support_targets - np.sum(support_alphas * support_targets * kernel_function(support_vectors, support_vectors, param), axis=0))	    return bias	    	def score_slmkc(X_test, kernel_function, param, C, model):	    support_vectors, support_targets, support_alphas, _ = model	    return np.sum(support_alphas * support_targets * kernel_function(support_vectors, X_test, param), axis=0) + compute_bias(kernel_function, param, C, model)	    	def test_slmkc(X_test, kernel_function, param, C, model):	    scores = score_slmkc(X_test, kernel_function, param, C, model)	    return np.sign(scores)	    	class SoftLargeMarginKernelClassifier(object):	    def __init__(self, C, kernel_function, param):	            self.C = C	            self.kernel_function = kernel_function	            self.param = param	            self.support_vectors = None	            self.support_targets = None	            self.support_alphas = None	            self.support_ids = None		    def fit(self, X, y):	        self.support_vectors, self.support_targets, self.support_alphas, self.support_ids = train_slmkc(X, y, self.C, self.kernel_function, self.param)		    def predict(self, X):	        return test_slmkc(X, self.kernel_function, self.param, self.C, (self.support_vectors, self.support_targets, self.support_alphas, self.support_ids))		    def decision_function(self, X):	        return score_slmkc(X, self.kernel_function, self.param, self.C, (self.support_vectors, self.support_targets, self.support_alphas, self.support_ids))		    	save_history()
2024-04-23-21-12-19 392 2 get_ipython().run_line_magic('matplotlib', 'inline')	import matplotlib.pyplot as plt	from mpl_toolkits.mplot3d import Axes3D	import numpy as np	import scipy as sp	import cvxopt	from submission_utils import save_history, check_and_prepare_for_submission	from warnings import simplefilter	# ignore all future warnings	simplefilter(action='ignore', category=FutureWarning)
