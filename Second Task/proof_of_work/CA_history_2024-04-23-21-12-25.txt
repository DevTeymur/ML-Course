2024-04-23-21-12-25 392 1 from cvxopt import matrix	from cvxopt import solvers		def make_H_k(X,t, kernel_function, param):	    n_samples = len(X)	    H = np.zeros((n_samples, n_samples))	    for i in range(n_samples):	        for j in range(n_samples):	            H[i, j] = t[i] * t[j] * kernel_function(X[i], X[j], param)	    return H	    	def setup_optimization_soft_k(X,t,C, kernel_function, param):	    n_samples = len(X)	    H = make_H_k(X, t, kernel_function, param)	    P = matrix(H, tc='d')	    q = matrix(-1.0, (n_samples, 1))	    G = matrix(np.diag(-1.0 * np.ones(n_samples)), tc='d')	    h = matrix(np.zeros(n_samples))	    A = matrix(t.reshape(1, -1), tc='d')	    b = matrix(0.0)	    return P, q, G, h, A, b	    	def compute_support_vectors(X,t,alphas, tolerance=1e-5):	    sv_idx = alphas > tolerance	    return X[sv_idx], t[sv_idx], alphas[sv_idx], sv_idx	    	def train_slmkc(X, t, C, kernel_function, param):	    n_samples = len(X)	    P, q, G, h, A, b = setup_optimization_soft_k(X, t, C, kernel_function, param)	    sol = solvers.qp(P, q, G, h, A, b)	    alphas = np.array(sol['x']).flatten()	    return compute_support_vectors(X, t, alphas)	    	def compute_bias(kernel_function, param, C, model):	    support_vectors, support_targets, support_alphas, _ = model	    bias = np.mean(support_targets - np.sum(support_alphas * support_targets * kernel_function(support_vectors, support_vectors, param), axis=0))	    return bias	    	def score_slmkc(X_test, kernel_function, param, C, model):	    support_vectors, support_targets, support_alphas, _ = model	    return np.sum(support_alphas * support_targets * kernel_function(support_vectors, X_test, param), axis=0) + compute_bias(kernel_function, param, C, model)	    	def test_slmkc(X_test, kernel_function, param, C, model):	    scores = score_slmkc(X_test, kernel_function, param, C, model)	    return np.sign(scores)	    	class SoftLargeMarginKernelClassifier(object):	    def __init__(self, C, kernel_function, param):	            self.C = C	            self.kernel_function = kernel_function	            self.param = param	            self.support_vectors = None	            self.support_targets = None	            self.support_alphas = None	            self.support_ids = None		    def fit(self, X, y):	        self.support_vectors, self.support_targets, self.support_alphas, self.support_ids = train_slmkc(X, y, self.C, self.kernel_function, self.param)		    def predict(self, X):	        return test_slmkc(X, self.kernel_function, self.param, self.C, (self.support_vectors, self.support_targets, self.support_alphas, self.support_ids))		    def decision_function(self, X):	        return score_slmkc(X, self.kernel_function, self.param, self.C, (self.support_vectors, self.support_targets, self.support_alphas, self.support_ids))		    	save_history()
2024-04-23-21-12-25 392 2 get_ipython().run_line_magic('matplotlib', 'inline')	import matplotlib.pyplot as plt	from mpl_toolkits.mplot3d import Axes3D	import numpy as np	import scipy as sp	import cvxopt	from submission_utils import save_history, check_and_prepare_for_submission	from warnings import simplefilter	# ignore all future warnings	simplefilter(action='ignore', category=FutureWarning)
2024-04-23-21-12-25 392 3 import random	    	def permute(seq):	    # Converting to list, permuting, and converting back to string	    seq_array = np.array(list(seq))	    return ''.join(np.random.permutation(seq_array))		def generate_master_sequence(alphabet_size, seq_length, start_char=70):	    return ''.join(chr(np.random.randint(start_char, start_char + alphabet_size)) for _ in range(seq_length))		def perturb(master_sequence, noise):	    seq_array = np.array(list(master_sequence))	    num_perturbations = int(len(seq_array) * noise)	    # Depending on the noise level swaping the places of random characters	    for _ in range(num_perturbations):	        i1, i2 = np.random.choice(len(seq_array), 2, replace=False)	        seq_array[i1], seq_array[i2] = seq_array[i2], seq_array[i1]	    return ''.join(seq_array)		def randomize_length(seqs, endpoint_trim_dim):	    randomized_seqs = []	    for seq in seqs:	        trim_length = np.random.randint(0, endpoint_trim_dim + 1)	        randomized_seqs.append(seq[trim_length:-trim_length])	    return randomized_seqs		def make_single_cluster_data(master_sequence, n_inliners, n_outliers, inliner_noise, outlier_noise, endpoint_trim_dim=None):	    inliners = [perturb(master_sequence, inliner_noise) for _ in range(n_inliners)]	    outliers = [perturb(permute(master_sequence), outlier_noise) for _ in range(n_outliers)]		    all_seqs = inliners + outliers 	        	    if endpoint_trim_dim is not None:	        all_seqs = randomize_length(all_seqs, endpoint_trim_dim)	    return all_seqs		def make_data(master_sequence, n_clusters, cluster_centres_noise, n_inliners, n_outliers, inliner_noise, outlier_noise, endpoint_trim_dim=None):	    sequences, targets = [], []	    for i in range(n_clusters):	        cluster_centre = perturb(master_sequence, cluster_centres_noise)	        cluster_seqs = make_single_cluster_data(cluster_centre, n_inliners, n_outliers, inliner_noise, outlier_noise, endpoint_trim_dim)	        sequences.extend(cluster_seqs)	        targets.extend([i] * len(cluster_seqs))	    return sequences, targets	    	save_history()
2024-04-23-21-12-25 392 4 # DELETE AT THE END		np.random.seed(42)		# For example 1	seq = "temperature"	permuted_seq = permute(seq)	print(f'Original sequence: {seq}, permuted sequence: {permuted_seq}')		# For example 2	master_seq = generate_master_sequence(alphabet_size=5, seq_length=10)	print("Master sequence:", master_seq)		# For example 3	perturbed_seq = perturb(master_seq, noise=0.8)	print("Perturbed sequence:", perturbed_seq)		# For example 4	seqs = ["salam", "temperature", "verynice"]	randomized_seqs = randomize_length(seqs, endpoint_trim_dim=2)	print("Randomized sequences:", randomized_seqs)		# For example 5	master_sequence = "againtemperature"	inlier_seqs = make_single_cluster_data(master_sequence, n_inliners=3, n_outliers=2, inliner_noise=0.1, outlier_noise=0.5)	print("Inlier sequences:", inlier_seqs[:3])	print("Inlier sequences:", inlier_seqs[3:])		# For example 6	master_sequence = "anotherwordthatdoesnotexist"	seqs, targets = make_data(master_sequence, n_clusters=2, cluster_centres_noise=0.1, n_inliners=3, n_outliers=2, inliner_noise=0.1, outlier_noise=0.5)	print("Generated sequences:", seqs)	print("Cluster labels:", targets)
2024-04-23-21-12-25 392 5 # This cell is reserved for the unit tests. Do not consider this cell. 
2024-04-23-21-12-25 392 6 # This cell is reserved for the unit tests. Do not consider this cell. 
2024-04-23-21-12-25 392 7 # This cell is reserved for the unit tests. Do not consider this cell. 
2024-04-23-21-12-25 392 8 # This cell is reserved for the unit tests. Do not consider this cell. 
2024-04-23-21-12-25 392 9 # This cell is reserved for the unit tests. Do not consider this cell. 
2024-04-23-21-12-25 392 10 # This cell is reserved for the unit tests. Do not consider this cell. 
