2024-04-24-23-11-48 393 1 get_ipython().run_line_magic('matplotlib', 'inline')	import matplotlib.pyplot as plt	from mpl_toolkits.mplot3d import Axes3D	import numpy as np	import scipy as sp	import cvxopt	from submission_utils import save_history, check_and_prepare_for_submission	from warnings import simplefilter	# ignore all future warnings	simplefilter(action='ignore', category=FutureWarning)
2024-04-24-23-11-48 393 2 import random	    	def permute(seq):	    # Converting to list, permuting, and converting back to string	    seq_array = np.array(list(seq))	    return ''.join(np.random.permutation(seq_array))		def generate_master_sequence(alphabet_size, seq_length, start_char=70):	    return ''.join(chr(np.random.randint(start_char, start_char + alphabet_size)) for _ in range(seq_length))		def perturb(master_sequence, noise):	    seq_array = np.array(list(master_sequence))	    num_perturbations = int(len(seq_array) * noise)	    # Depending on the noise level swaping the places of random characters	    for _ in range(num_perturbations):	        i1, i2 = np.random.choice(len(seq_array), 2, replace=False)	        seq_array[i1], seq_array[i2] = seq_array[i2], seq_array[i1]	    return ''.join(seq_array)		def randomize_length(seqs, endpoint_trim_dim):	    randomized_seqs = []	    for seq in seqs:	        trim_length = np.random.randint(0, endpoint_trim_dim + 1)	        randomized_seqs.append(seq[trim_length:-trim_length])	    return randomized_seqs		def make_single_cluster_data(master_sequence, n_inliners, n_outliers, inliner_noise, outlier_noise, endpoint_trim_dim=None):	    inliners = [perturb(master_sequence, inliner_noise) for _ in range(n_inliners)]	    # outliers = [perturb(permute(master_sequence), outlier_noise) for _ in range(n_outliers)]	    outliers = [perturb(master_sequence, outlier_noise) for _ in range(n_outliers)]		    all_seqs = inliners + outliers 	        	    if endpoint_trim_dim is not None:	        all_seqs = randomize_length(all_seqs, endpoint_trim_dim)	    	    return all_seqs		def make_data(master_sequence, n_clusters, cluster_centres_noise, n_inliners, n_outliers, inliner_noise, outlier_noise, endpoint_trim_dim=None):	    sequences, targets = [], []	    for i in range(n_clusters):	        cluster_centre = perturb(master_sequence, cluster_centres_noise)	        cluster_seqs = make_single_cluster_data(cluster_centre, n_inliners, n_outliers, inliner_noise, outlier_noise, endpoint_trim_dim)	        sequences.extend(cluster_seqs)	        targets.extend([i] * len(cluster_seqs))	    return sequences, targets	    	save_history()
2024-04-24-23-11-48 393 3 def histogram_vectorizer(seqs):	    def convert_to_int_sequence(seq):	        return [ord(char) for char in seq]		    def single_histogram_vectorizer(seq):	        int_seq = convert_to_int_sequence(seq)	        vector = [int_seq.count(i) for i in range(256)] # counting eveery ASCII character	        return vector		    vectorized_seqs = [single_histogram_vectorizer(seq) for seq in seqs]	    max_elem = max(max(row) for row in vectorized_seqs)	    print("Maximum element in the 2D array:", max_elem)	    flat_array = [elem for row in vectorized_seqs for elem in row]	    average = sum(flat_array) / len(flat_array)	    print("Average of the elements in the 2D array:", average)	    return np.array(vectorized_seqs)	        		from sklearn.decomposition import PCA		def pca_plot(X, y=None):	    # Performing PCA and reducing the dimentions to 2D	    pca = PCA(n_components=2)	    X_pca = pca.fit_transform(X)		    plt.figure(figsize=(8, 6))	    if y is None:	        plt.scatter(X_pca[:, 0], X_pca[:, 1], s=50, alpha=0.8, cmap='viridis')	    else:	        colors_for_labels = ['r', 'b', 'g', 'y', 'c', 'm', 'k', 'w']	        unique_labels = np.unique(y)	        for label in unique_labels:	            plt.scatter(X_pca[y == label, 0], X_pca[y == label, 1], c=colors_for_labels[label], alpha=0.8)	    plt.xlabel('PCA1')	    plt.ylabel('PCA2')	    plt.show()		save_history()
2024-04-24-23-11-48 393 4 master_sequence = generate_master_sequence(alphabet_size=4, seq_length=150, start_char=68)	n_instances = 200	n_outliers = n_instances//9	n_inliners = n_instances - n_outliers	seqs, targets = make_data(	    master_sequence, 	    n_clusters=2,	    cluster_centres_noise=.5,	    n_inliners=n_inliners, 	    n_outliers=0, 	    inliner_noise=.15, 	    outlier_noise=.99, 	    endpoint_trim_dim=15)			X = histogram_vectorizer(seqs)	pca_plot(X, y=targets)
2024-04-24-23-11-48 393 5 def histogram_vectorizer(seqs):	    def convert_to_int_sequence(seq):	        return [ord(char) for char in seq]		    def single_histogram_vectorizer(seq):	        int_seq = convert_to_int_sequence(seq)	        vector = [int_seq.count(i) for i in range(256)] # counting eveery ASCII character	        return vector		    vectorized_seqs = [single_histogram_vectorizer(seq) for seq in seqs]	    return np.array(vectorized_seqs)	        		from sklearn.decomposition import PCA		def pca_plot(X, y=None):	    # Performing PCA and reducing the dimentions to 2D	    pca = PCA(n_components=2)	    X_pca = pca.fit_transform(X)		    plt.figure(figsize=(8, 6))	    if y is None:	        plt.scatter(X_pca[:, 0], X_pca[:, 1], s=50, alpha=0.8, cmap='viridis')	    else:	        colors_for_labels = ['r', 'b', 'g', 'y', 'c', 'm', 'k', 'w']	        unique_labels = np.unique(y)	        for label in unique_labels:	            plt.scatter(X_pca[y == label, 0], X_pca[y == label, 1], c=colors_for_labels[label], alpha=0.8)	    plt.xlabel('PCA1')	    plt.ylabel('PCA2')	    plt.show()		save_history()
2024-04-24-23-11-48 393 6 def histogram_vectorizer(seqs):	    def convert_to_int_sequence(seq):	        return [ord(char) for char in seq]		    def single_histogram_vectorizer(seq):	        int_seq = convert_to_int_sequence(seq)	        max_elem = max(max(row) for row in int_seq)	        print("Maximum element in the 2D array:", max_elem)	        flat_array = [elem for row in int_seq for elem in row]	        average = sum(flat_array) / len(flat_array)	        print("Average of the elements in the 2D array:", average)	        vector = [int_seq.count(i) for i in range(256)] # counting eveery ASCII character	        return vector		    vectorized_seqs = [single_histogram_vectorizer(seq) for seq in seqs]	    return np.array(vectorized_seqs)	        		from sklearn.decomposition import PCA		def pca_plot(X, y=None):	    # Performing PCA and reducing the dimentions to 2D	    pca = PCA(n_components=2)	    X_pca = pca.fit_transform(X)		    plt.figure(figsize=(8, 6))	    if y is None:	        plt.scatter(X_pca[:, 0], X_pca[:, 1], s=50, alpha=0.8, cmap='viridis')	    else:	        colors_for_labels = ['r', 'b', 'g', 'y', 'c', 'm', 'k', 'w']	        unique_labels = np.unique(y)	        for label in unique_labels:	            plt.scatter(X_pca[y == label, 0], X_pca[y == label, 1], c=colors_for_labels[label], alpha=0.8)	    plt.xlabel('PCA1')	    plt.ylabel('PCA2')	    plt.show()		save_history()
2024-04-24-23-11-48 393 7 def histogram_vectorizer(seqs):	    def convert_to_int_sequence(seq):	        return [ord(char) for char in seq]		    def single_histogram_vectorizer(seq):	        int_seq = convert_to_int_sequence(seq)	        print(int_seq)	        vector = [int_seq.count(i) for i in range(256)] # counting eveery ASCII character	        return vector		    vectorized_seqs = [single_histogram_vectorizer(seq) for seq in seqs]	    return np.array(vectorized_seqs)	        		from sklearn.decomposition import PCA		def pca_plot(X, y=None):	    # Performing PCA and reducing the dimentions to 2D	    pca = PCA(n_components=2)	    X_pca = pca.fit_transform(X)		    plt.figure(figsize=(8, 6))	    if y is None:	        plt.scatter(X_pca[:, 0], X_pca[:, 1], s=50, alpha=0.8, cmap='viridis')	    else:	        colors_for_labels = ['r', 'b', 'g', 'y', 'c', 'm', 'k', 'w']	        unique_labels = np.unique(y)	        for label in unique_labels:	            plt.scatter(X_pca[y == label, 0], X_pca[y == label, 1], c=colors_for_labels[label], alpha=0.8)	    plt.xlabel('PCA1')	    plt.ylabel('PCA2')	    plt.show()		save_history()
2024-04-24-23-11-48 393 8 def histogram_vectorizer(seqs):	    def convert_to_int_sequence(seq):	        return [ord(char) for char in seq]		    def single_histogram_vectorizer(seq):	        int_seq = convert_to_int_sequence(seq)	        print(int_seq)	        vector = [int_seq.count(i) for i in range(256)] # counting eveery ASCII character	        return vector		    vectorized_seqs = [single_histogram_vectorizer(seq) for seq in seqs]	    return np.array(vectorized_seqs)	        		from sklearn.decomposition import PCA		def pca_plot(X, y=None):	    # Performing PCA and reducing the dimentions to 2D	    pca = PCA(n_components=2)	    X_pca = pca.fit_transform(X)		    plt.figure(figsize=(8, 6))	    if y is None:	        plt.scatter(X_pca[:, 0], X_pca[:, 1], s=50, alpha=0.8, cmap='viridis')	    else:	        colors_for_labels = ['r', 'b', 'g', 'y', 'c', 'm', 'k', 'w']	        unique_labels = np.unique(y)	        for label in unique_labels:	            plt.scatter(X_pca[y == label, 0], X_pca[y == label, 1], c=colors_for_labels[label], alpha=0.8)	    plt.xlabel('PCA1')	    plt.ylabel('PCA2')	    plt.show()		save_history()
2024-04-24-23-11-48 393 9 master_sequence = generate_master_sequence(alphabet_size=4, seq_length=150, start_char=68)	n_instances = 200	n_outliers = n_instances//9	n_inliners = n_instances - n_outliers	seqs, targets = make_data(	    master_sequence, 	    n_clusters=2,	    cluster_centres_noise=.5,	    n_inliners=n_inliners, 	    n_outliers=0, 	    inliner_noise=.15, 	    outlier_noise=.99, 	    endpoint_trim_dim=15)			X = histogram_vectorizer(seqs)	pca_plot(X, y=targets)
2024-04-24-23-11-48 393 10 def histogram_vectorizer(seqs):	    def convert_to_int_sequence(seq):	        return [ord(char) for char in seq]		    def single_histogram_vectorizer(seq):	        int_seq = convert_to_int_sequence(seq)	        vector = [int_seq.count(i) for i in range(256)] # counting eveery ASCII character	        max_elem = max(max(row) for row in vector)	        print("Maximum element in the 2D array:", max_elem)	        flat_array = [elem for row in vector for elem in row]	        average = sum(flat_array) / len(flat_array)	        print("Average of the elements in the 2D array:", average)	        return vector		    vectorized_seqs = [single_histogram_vectorizer(seq) for seq in seqs]	    return np.array(vectorized_seqs)	        		from sklearn.decomposition import PCA		def pca_plot(X, y=None):	    # Performing PCA and reducing the dimentions to 2D	    pca = PCA(n_components=2)	    X_pca = pca.fit_transform(X)		    plt.figure(figsize=(8, 6))	    if y is None:	        plt.scatter(X_pca[:, 0], X_pca[:, 1], s=50, alpha=0.8, cmap='viridis')	    else:	        colors_for_labels = ['r', 'b', 'g', 'y', 'c', 'm', 'k', 'w']	        unique_labels = np.unique(y)	        for label in unique_labels:	            plt.scatter(X_pca[y == label, 0], X_pca[y == label, 1], c=colors_for_labels[label], alpha=0.8)	    plt.xlabel('PCA1')	    plt.ylabel('PCA2')	    plt.show()		save_history()
2024-04-24-23-11-48 393 11 master_sequence = generate_master_sequence(alphabet_size=4, seq_length=150, start_char=68)	n_instances = 200	n_outliers = n_instances//9	n_inliners = n_instances - n_outliers	seqs, targets = make_data(	    master_sequence, 	    n_clusters=2,	    cluster_centres_noise=.5,	    n_inliners=n_inliners, 	    n_outliers=0, 	    inliner_noise=.15, 	    outlier_noise=.99, 	    endpoint_trim_dim=15)			X = histogram_vectorizer(seqs)	pca_plot(X, y=targets)
2024-04-24-23-11-48 393 12 def histogram_vectorizer(seqs):	    def convert_to_int_sequence(seq):	        return [ord(char) for char in seq]		    def single_histogram_vectorizer(seq):	        int_seq = convert_to_int_sequence(seq)	        vector = [int_seq.count(i) for i in range(256)] # counting eveery ASCII character	        print(vector)	        return vector		    vectorized_seqs = [single_histogram_vectorizer(seq) for seq in seqs]	    return np.array(vectorized_seqs)	        		from sklearn.decomposition import PCA		def pca_plot(X, y=None):	    # Performing PCA and reducing the dimentions to 2D	    pca = PCA(n_components=2)	    X_pca = pca.fit_transform(X)		    plt.figure(figsize=(8, 6))	    if y is None:	        plt.scatter(X_pca[:, 0], X_pca[:, 1], s=50, alpha=0.8, cmap='viridis')	    else:	        colors_for_labels = ['r', 'b', 'g', 'y', 'c', 'm', 'k', 'w']	        unique_labels = np.unique(y)	        for label in unique_labels:	            plt.scatter(X_pca[y == label, 0], X_pca[y == label, 1], c=colors_for_labels[label], alpha=0.8)	    plt.xlabel('PCA1')	    plt.ylabel('PCA2')	    plt.show()		save_history()
2024-04-24-23-11-48 393 13 master_sequence = generate_master_sequence(alphabet_size=4, seq_length=150, start_char=68)	n_instances = 200	n_outliers = n_instances//9	n_inliners = n_instances - n_outliers	seqs, targets = make_data(	    master_sequence, 	    n_clusters=2,	    cluster_centres_noise=.5,	    n_inliners=n_inliners, 	    n_outliers=0, 	    inliner_noise=.15, 	    outlier_noise=.99, 	    endpoint_trim_dim=15)			X = histogram_vectorizer(seqs)	pca_plot(X, y=targets)
2024-04-24-23-11-48 393 14 def histogram_vectorizer(seqs):	    def convert_to_int_sequence(seq):	        return [ord(char) for char in seq]		    def single_histogram_vectorizer(seq):	        int_seq = convert_to_int_sequence(seq)	        vector = [int_seq.count(i) for i in range(256)] # counting eveery ASCII character	        # print(vector)	        return vector		    vectorized_seqs = [single_histogram_vectorizer(seq) for seq in seqs]	    return np.array(vectorized_seqs)	        		from sklearn.decomposition import PCA		def pca_plot(X, y=None):	    # Performing PCA and reducing the dimentions to 2D	    pca = PCA(n_components=2)	    X_pca = pca.fit_transform(X)		    plt.figure(figsize=(8, 6))	    if y is None:	        plt.scatter(X_pca[:, 0], X_pca[:, 1], s=50, alpha=0.8, cmap='viridis')	    else:	        colors_for_labels = ['r', 'b', 'g', 'y', 'c', 'm', 'k', 'w']	        unique_labels = np.unique(y)	        for label in unique_labels:	            plt.scatter(X_pca[y == label, 0], X_pca[y == label, 1], c=colors_for_labels[label], alpha=0.8)	    plt.xlabel('PCA1')	    plt.ylabel('PCA2')	    plt.show()		save_history()
2024-04-24-23-11-48 393 15 master_sequence = generate_master_sequence(alphabet_size=4, seq_length=150, start_char=68)	n_instances = 200	n_outliers = n_instances//9	n_inliners = n_instances - n_outliers	seqs, targets = make_data(	    master_sequence, 	    n_clusters=2,	    cluster_centres_noise=.5,	    n_inliners=n_inliners, 	    n_outliers=0, 	    inliner_noise=.15, 	    outlier_noise=.99, 	    endpoint_trim_dim=15)			X = histogram_vectorizer(seqs)	max_elem = max(max(row) for row in X)	print("Maximum element in the 2D array:", max_elem)	flat_array = [elem for row in X for elem in row]	average = sum(flat_array) / len(flat_array)	print("Average of the elements in the 2D array:", average)	pca_plot(X, y=targets)
2024-04-24-23-11-48 393 16 master_sequence = generate_master_sequence(alphabet_size=4, seq_length=150, start_char=68)	n_instances = 200	n_outliers = n_instances//9	n_inliners = n_instances - n_outliers	seqs, targets = make_data(	    master_sequence, 	    n_clusters=2,	    cluster_centres_noise=.5,	    n_inliners=n_inliners, 	    n_outliers=0, 	    inliner_noise=.15, 	    outlier_noise=.99, 	    endpoint_trim_dim=15)			X = histogram_vectorizer(seqs)	max_elem = max(max(row) for row in X)	print("Maximum element in the 2D array:", max_elem)	flat_array = [elem for row in X for elem in row]	average = sum(flat_array) / len(flat_array)	print("Average of the elements in the 2D array:", average)	pca_plot(X, y=targets)
2024-04-24-23-11-48 393 17 import random	random.seed(0)	    	def permute(seq):	    # Converting to list, permuting, and converting back to string	    seq_array = np.array(list(seq))	    return ''.join(np.random.permutation(seq_array))		def generate_master_sequence(alphabet_size, seq_length, start_char=70):	    return ''.join(chr(np.random.randint(start_char, start_char + alphabet_size)) for _ in range(seq_length))		def perturb(master_sequence, noise):	    seq_array = np.array(list(master_sequence))	    num_perturbations = int(len(seq_array) * noise)	    # Depending on the noise level swaping the places of random characters	    for _ in range(num_perturbations):	        i1, i2 = np.random.choice(len(seq_array), 2, replace=False)	        seq_array[i1], seq_array[i2] = seq_array[i2], seq_array[i1]	    return ''.join(seq_array)		def randomize_length(seqs, endpoint_trim_dim):	    randomized_seqs = []	    for seq in seqs:	        trim_length = np.random.randint(0, endpoint_trim_dim + 1)	        randomized_seqs.append(seq[trim_length:-trim_length])	    return randomized_seqs		def make_single_cluster_data(master_sequence, n_inliners, n_outliers, inliner_noise, outlier_noise, endpoint_trim_dim=None):	    inliners = [perturb(master_sequence, inliner_noise) for _ in range(n_inliners)]	    # outliers = [perturb(permute(master_sequence), outlier_noise) for _ in range(n_outliers)]	    outliers = [perturb(master_sequence, outlier_noise) for _ in range(n_outliers)]		    all_seqs = inliners + outliers 	        	    if endpoint_trim_dim is not None:	        all_seqs = randomize_length(all_seqs, endpoint_trim_dim)	    	    return all_seqs		def make_data(master_sequence, n_clusters, cluster_centres_noise, n_inliners, n_outliers, inliner_noise, outlier_noise, endpoint_trim_dim=None):	    sequences, targets = [], []	    for i in range(n_clusters):	        cluster_centre = perturb(master_sequence, cluster_centres_noise)	        cluster_seqs = make_single_cluster_data(cluster_centre, n_inliners, n_outliers, inliner_noise, outlier_noise, endpoint_trim_dim)	        sequences.extend(cluster_seqs)	        targets.extend([i] * len(cluster_seqs))	    return sequences, targets	    	save_history()
2024-04-24-23-11-48 393 18 master_sequence = generate_master_sequence(alphabet_size=4, seq_length=150, start_char=68)	n_instances = 200	n_outliers = n_instances//9	n_inliners = n_instances - n_outliers	seqs, targets = make_data(	    master_sequence, 	    n_clusters=2,	    cluster_centres_noise=.5,	    n_inliners=n_inliners, 	    n_outliers=0, 	    inliner_noise=.15, 	    outlier_noise=.99, 	    endpoint_trim_dim=15)			X = histogram_vectorizer(seqs)	max_elem = max(max(row) for row in X)	print("Maximum element in the 2D array:", max_elem)	flat_array = [elem for row in X for elem in row]	average = sum(flat_array) / len(flat_array)	print("Average of the elements in the 2D array:", average)	pca_plot(X, y=targets)
2024-04-24-23-11-48 393 19 master_sequence = generate_master_sequence(alphabet_size=4, seq_length=150, start_char=68)	n_instances = 200	n_outliers = n_instances//9	n_inliners = n_instances - n_outliers	seqs, targets = make_data(	    master_sequence, 	    n_clusters=2,	    cluster_centres_noise=.5,	    n_inliners=n_inliners, 	    n_outliers=0, 	    inliner_noise=.15, 	    outlier_noise=.99, 	    endpoint_trim_dim=15)			X = histogram_vectorizer(seqs)	max_elem = max(max(row) for row in X)	print("Maximum element in the 2D array:", max_elem)	flat_array = [elem for row in X for elem in row]	average = sum(flat_array) / len(flat_array)	print("Average of the elements in the 2D array:", average)	pca_plot(X, y=targets)
2024-04-24-23-11-48 393 20 def histogram_vectorizer(seqs):	    """	    Converting a list of sequences into a matrix of sequence vectors.		    Args:	        seqs: a list of strings, each string represents a sequence.	    Returns:	        a 2D numpy array of size (len(seqs), 256) representing the histogram of each sequence.	    """	    def convert_to_int_sequence(seq):	        return [ord(char) for char in seq]		    def single_histogram_vectorizer(seq):	        int_seq = convert_to_int_sequence(seq)	        vector = [int_seq.count(i) for i in range(256)] # counting eveery ASCII character	        # print(vector)	        return vector		    vectorized_seqs = [single_histogram_vectorizer(seq) for seq in seqs]	    return np.array(vectorized_seqs)	        		from sklearn.decomposition import PCA		def pca_plot(X, y=None):	    """	    Perform PCA on the input data and plot the data points in a 2D graph.		    Args:	        X: a 2D numpy array of size (n, 256) representing the histogram of each sequence.	        y: a 1D numpy array of size (n,) representing the cluster index of each sequence.		    Returns:	        None	    """	    # Performing PCA and reducing the dimentions to 2D	    pca = PCA(n_components=2)	    X_pca = pca.fit_transform(X)	    max_index = np.argmax(X_pca[:, 0])  # Assuming you want to delete based on the first component, adjust if necessary	    X_pca = np.delete(X_pca, max_index, axis=0)	    y = np.delete(y, max_index, axis=0)		    plt.figure(figsize=(8, 6))	    if y is None:	        plt.scatter(X_pca[:, 0], X_pca[:, 1], s=50, alpha=0.8, cmap='viridis')	    else:	        colors_for_labels = ['r', 'b', 'g', 'y', 'c', 'm', 'k', 'w']	        unique_labels = np.unique(y)	        for label in unique_labels:	            plt.scatter(X_pca[y == label, 0], X_pca[y == label, 1], c=colors_for_labels[label], alpha=0.8)	    plt.xlabel('PCA1')	    plt.ylabel('PCA2')	    plt.show()		save_history()
2024-04-24-23-11-48 393 21 def histogram_vectorizer(seqs):	    """	    Converting a list of sequences into a matrix of sequence vectors.		    Args:	        seqs: a list of strings, each string represents a sequence.	    Returns:	        a 2D numpy array of size (len(seqs), 256) representing the histogram of each sequence.	    """	    def convert_to_int_sequence(seq):	        return [ord(char) for char in seq]		    def single_histogram_vectorizer(seq):	        int_seq = convert_to_int_sequence(seq)	        vector = [int_seq.count(i) for i in range(256)] # counting eveery ASCII character	        # print(vector)	        return vector		    vectorized_seqs = [single_histogram_vectorizer(seq) for seq in seqs]	    return np.array(vectorized_seqs)	        		from sklearn.decomposition import PCA		def pca_plot(X, y=None):	    """	    Perform PCA on the input data and plot the data points in a 2D graph.		    Args:	        X: a 2D numpy array of size (n, 256) representing the histogram of each sequence.	        y: a 1D numpy array of size (n,) representing the cluster index of each sequence.		    Returns:	        None	    """	    # Performing PCA and reducing the dimentions to 2D	    pca = PCA(n_components=2)	    X_pca = pca.fit_transform(X)	    max_index = np.argmax(X_pca[:, 0])  # Assuming you want to delete based on the first component, adjust if necessary	    X_pca = np.delete(X_pca, max_index, axis=0)	    y = np.delete(y, max_index, axis=0)		    plt.figure(figsize=(8, 6))	    if y is None:	        plt.scatter(X_pca[:, 0], X_pca[:, 1], s=50, alpha=0.8, cmap='viridis')	    else:	        colors_for_labels = ['r', 'b', 'g', 'y', 'c', 'm', 'k', 'w']	        unique_labels = np.unique(y)	        for label in unique_labels:	            plt.scatter(X_pca[y == label, 0], X_pca[y == label, 1], c=colors_for_labels[label], alpha=0.8)	    plt.xlabel('PCA1')	    plt.ylabel('PCA2')	    plt.show()		save_history()
2024-04-24-23-11-48 393 22 def histogram_vectorizer(seqs):	    """	    Converting a list of sequences into a matrix of sequence vectors.		    Args:	        seqs: a list of strings, each string represents a sequence.	    Returns:	        a 2D numpy array of size (len(seqs), 256) representing the histogram of each sequence.	    """	    def convert_to_int_sequence(seq):	        return [ord(char) for char in seq]		    def single_histogram_vectorizer(seq):	        int_seq = convert_to_int_sequence(seq)	        vector = [int_seq.count(i) for i in range(256)] # counting eveery ASCII character	        # print(vector)	        return vector		    vectorized_seqs = [single_histogram_vectorizer(seq) for seq in seqs]	    return np.array(vectorized_seqs)	        		from sklearn.decomposition import PCA		def pca_plot(X, y=None):	    """	    Perform PCA on the input data and plot the data points in a 2D graph.		    Args:	        X: a 2D numpy array of size (n, 256) representing the histogram of each sequence.	        y: a 1D numpy array of size (n,) representing the cluster index of each sequence.		    Returns:	        None	    """	    # Performing PCA and reducing the dimentions to 2D	    pca = PCA(n_components=2)	    X_pca = pca.fit_transform(X)	    max_index = np.argmax(X_pca[:, 0])  # Assuming you want to delete based on the first component, adjust if necessary	    X_pca = np.delete(X_pca, max_index, axis=0)	    y = np.delete(y, max_index, axis=0)		    plt.figure(figsize=(8, 6))	    if y is None:	        plt.scatter(X_pca[:, 0], X_pca[:, 1], s=50, alpha=0.8, cmap='viridis')	    else:	        colors_for_labels = ['r', 'b', 'g', 'y', 'c', 'm', 'k', 'w']	        unique_labels = np.unique(y)	        for label in unique_labels:	            plt.scatter(X_pca[y == label, 0], X_pca[y == label, 1], c=colors_for_labels[label], alpha=0.8)	    plt.xlabel('PCA1')	    plt.ylabel('PCA2')	    plt.show()		save_history()
2024-04-24-23-11-48 393 23 master_sequence = generate_master_sequence(alphabet_size=4, seq_length=150, start_char=68)	n_instances = 200	n_outliers = n_instances//9	n_inliners = n_instances - n_outliers	seqs, targets = make_data(	    master_sequence, 	    n_clusters=2,	    cluster_centres_noise=.5,	    n_inliners=n_inliners, 	    n_outliers=0, 	    inliner_noise=.15, 	    outlier_noise=.99, 	    endpoint_trim_dim=15)			X = histogram_vectorizer(seqs)	pca_plot(X, y=targets)
2024-04-24-23-11-48 393 24 def histogram_vectorizer(seqs):	    """	    Converting a list of sequences into a matrix of sequence vectors.		    Args:	        seqs: a list of strings, each string represents a sequence.	    Returns:	        a 2D numpy array of size (len(seqs), 256) representing the histogram of each sequence.	    """	    def convert_to_int_sequence(seq):	        return [ord(char) for char in seq]		    def single_histogram_vectorizer(seq):	        int_seq = convert_to_int_sequence(seq)	        vector = [int_seq.count(i) for i in range(256)] # counting eveery ASCII character	        # print(vector)	        return vector		    vectorized_seqs = [single_histogram_vectorizer(seq) for seq in seqs]	    return np.array(vectorized_seqs)	        		from sklearn.decomposition import PCA		def pca_plot(X, y=None):	    """	    Perform PCA on the input data and plot the data points in a 2D graph.		    Args:	        X: a 2D numpy array of size (n, 256) representing the histogram of each sequence.	        y: a 1D numpy array of size (n,) representing the cluster index of each sequence.		    Returns:	        None	    """	    # Performing PCA and reducing the dimentions to 2D	    pca = PCA(n_components=2)	    X_pca = pca.fit_transform(X)	    # max_index = np.argmax(X_pca[:, 0])	    # X_pca = np.delete(X_pca, max_index, axis=0)	    # y = np.delete(y, max_index, axis=0)		    print(sorted(X_pca[:, 0], reverse=True)[:10])	    print(sorted(X_pca[:, 1], reverse=True)[:10])	    	    plt.figure(figsize=(8, 6))	    if y is None:	        plt.scatter(X_pca[:, 0], X_pca[:, 1], s=50, alpha=0.8, cmap='viridis')	    else:	        colors_for_labels = ['r', 'b', 'g', 'y', 'c', 'm', 'k', 'w']	        unique_labels = np.unique(y)	        for label in unique_labels:	            plt.scatter(X_pca[y == label, 0], X_pca[y == label, 1], c=colors_for_labels[label], alpha=0.8)	    plt.xlabel('PCA1')	    plt.ylabel('PCA2')	    plt.show()		save_history()
2024-04-24-23-11-48 393 25 master_sequence = generate_master_sequence(alphabet_size=4, seq_length=150, start_char=68)	n_instances = 200	n_outliers = n_instances//9	n_inliners = n_instances - n_outliers	seqs, targets = make_data(	    master_sequence, 	    n_clusters=2,	    cluster_centres_noise=.5,	    n_inliners=n_inliners, 	    n_outliers=0, 	    inliner_noise=.15, 	    outlier_noise=.99, 	    endpoint_trim_dim=15)			X = histogram_vectorizer(seqs)	pca_plot(X, y=targets)
2024-04-24-23-11-48 393 26 master_sequence = generate_master_sequence(alphabet_size=40, seq_length=150, start_char=68)	n_instances = 200	n_outliers = n_instances//9	n_inliners = n_instances - n_outliers	seqs, targets = make_data(	    master_sequence, 	    n_clusters=2,	    cluster_centres_noise=.5,	    n_inliners=n_inliners, 	    n_outliers=0, 	    inliner_noise=.15, 	    outlier_noise=.99, 	    endpoint_trim_dim=15)			X = histogram_vectorizer(seqs)	pca_plot(X, y=targets)
2024-04-24-23-11-48 393 27 master_sequence = generate_master_sequence(alphabet_size=256, seq_length=150, start_char=68)	n_instances = 200	n_outliers = n_instances//9	n_inliners = n_instances - n_outliers	seqs, targets = make_data(	    master_sequence, 	    n_clusters=2,	    cluster_centres_noise=.5,	    n_inliners=n_inliners, 	    n_outliers=0, 	    inliner_noise=.15, 	    outlier_noise=.99, 	    endpoint_trim_dim=15)			X = histogram_vectorizer(seqs)	pca_plot(X, y=targets)
2024-04-24-23-11-48 393 28 master_sequence = generate_master_sequence(alphabet_size=1, seq_length=150, start_char=68)	n_instances = 200	n_outliers = n_instances//9	n_inliners = n_instances - n_outliers	seqs, targets = make_data(	    master_sequence, 	    n_clusters=2,	    cluster_centres_noise=.5,	    n_inliners=n_inliners, 	    n_outliers=0, 	    inliner_noise=.15, 	    outlier_noise=.99, 	    endpoint_trim_dim=15)			X = histogram_vectorizer(seqs)	pca_plot(X, y=targets)
2024-04-24-23-11-48 393 29 master_sequence = generate_master_sequence(alphabet_size=2, seq_length=150, start_char=68)	n_instances = 200	n_outliers = n_instances//9	n_inliners = n_instances - n_outliers	seqs, targets = make_data(	    master_sequence, 	    n_clusters=2,	    cluster_centres_noise=.5,	    n_inliners=n_inliners, 	    n_outliers=0, 	    inliner_noise=.15, 	    outlier_noise=.99, 	    endpoint_trim_dim=15)			X = histogram_vectorizer(seqs)	pca_plot(X, y=targets)
2024-04-24-23-11-48 393 30 master_sequence = generate_master_sequence(alphabet_size=4, seq_length=150, start_char=68)	n_instances = 200	n_outliers = n_instances//9	n_inliners = n_instances - n_outliers	seqs, targets = make_data(	    master_sequence, 	    n_clusters=2,	    cluster_centres_noise=.5,	    n_inliners=n_inliners, 	    n_outliers=0, 	    inliner_noise=.15, 	    outlier_noise=.99, 	    endpoint_trim_dim=15)			X = histogram_vectorizer(seqs)	pca_plot(X, y=targets)
